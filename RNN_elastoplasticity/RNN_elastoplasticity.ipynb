{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN for path-dependent plasticity\n",
    "\n",
    "[Reference](https://doi.org/10.1016/j.jmps.2020.103972):\n",
    "Gorji, M. B., Mozaffar, M., Heidenreich, J. N., Cao, J., & Mohr, D. (2020). On the potential of recurrent neural networks for modeling path dependent plasticity. *Journal of the Mechanics and Physics of Solids*, 143, 103972.\n",
    "\n",
    "Plasticity model: Anisotropic Yld2000-2d with homogeneous anisotropic hardening\n",
    "\n",
    "ML model: Gated recurrent units (GRU) + fully-connected layer (for plane stress only?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FCNN model for UT with reveral loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def interpolate(xin, yin, reverse=False):\n",
    "\n",
    "    strain = np.linspace(min(xin), max(xin), 1000) if not reverse else np.linspace(max(xin), min(xin), 1000)\n",
    "    stress = np.interp(strain, xin, yin) if not reverse else np.interp(strain, xin[::-1], yin[::-1])\n",
    "\n",
    "    return strain, stress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x28f1b8763f0>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "excel_fpath = \"Reproduction_Mohr_2020_JMPS.xlsx\"\n",
    "sheet = 'UT w reversal'\n",
    "df = pd.read_excel(excel_fpath, sheet_name=sheet, header=9, usecols='F:P')\n",
    "\n",
    "df['RF2'] = df['RF2 Node 3'] + df['RF2 Node 4']\n",
    "df['U2'] = df['U2 Node 3']\n",
    "\n",
    "df['strain_true'] = np.log(1+df['U2'])\n",
    "df['stress_true'] = df['RF2'] * (1+df['U2'])\n",
    "\n",
    "ind_max = df['stress_true'].idxmax()\n",
    "strain1, stress1 = interpolate(df['strain_true'][:ind_max+1], df['stress_true'][:ind_max+1])\n",
    "strain2, stress2 = interpolate(df['strain_true'][ind_max:], df['stress_true'][ind_max:], reverse=True)\n",
    "strain = np.concatenate((strain1, strain2))\n",
    "stress = np.concatenate((stress1, stress2))\n",
    "strain_inc = np.diff(strain)\n",
    "strain_sum = np.cumsum(abs(strain_inc))\n",
    "strain_sum = np.concatenate(([0], strain_sum))  # Add zero at the beginning\n",
    "print(strain_sum.shape)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "df.plot(x='strain_true', y='stress_true', ax=ax, label='FEA')\n",
    "ax.plot(strain, stress, label='Interpolated', color='r', linestyle='--')\n",
    "ax.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using {device} device')\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, n_hl, n_npl):\n",
    "        super(Net, self).__init__()\n",
    "        self.nn_stack = nn.Sequential(\n",
    "            nn.Linear(2, n_npl),\n",
    "            nn.Tanh(),\n",
    "            *[nn.Sequential(nn.Linear(n_npl, n_npl), nn.Tanh()) for _ in range(n_hl)],\n",
    "            nn.Linear(n_npl, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.nn_stack(input)\n",
    "        return output\n",
    "\n",
    "def train(X, y, batch_size, model, loss_fn, optimizer):\n",
    "\n",
    "    size = len(X)\n",
    "    model.train()\n",
    "    X, y = shuffle(X, y)\n",
    "    X_batch = torch.tensor(X, dtype=torch.float32).view(-1, batch_size, 2)\n",
    "    y_batch = torch.tensor(y, dtype=torch.float32).view(-1, batch_size, 1)\n",
    "    size = len(X_batch)\n",
    "    train_loss = 0\n",
    "    for batch, (X, y) in enumerate(zip(X_batch, y_batch)):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss /= size\n",
    "    print('Training loss:', train_loss)\n",
    "    return train_loss\n",
    "\n",
    "def test(X, y, model, loss_fn):\n",
    "    size = len(X)\n",
    "    model.eval()\n",
    "    # test_loss = 0\n",
    "    X_batch = torch.tensor(X, dtype=torch.float32)\n",
    "    y_batch = torch.tensor(y, dtype=torch.float32)\n",
    "    with torch.no_grad():\n",
    "        pred = model(X_batch.to(device))\n",
    "        test_loss = loss_fn(pred, y_batch.to(device)).item()\n",
    "\n",
    "    # test_loss /= size\n",
    "    print(f'Test loss: {test_loss:>8f} \\n')\n",
    "    return test_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (nn_stack): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=20, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=20, out_features=20, bias=True)\n",
      "      (1): Tanh()\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): Linear(in_features=20, out_features=20, bias=True)\n",
      "      (1): Tanh()\n",
      "    )\n",
      "    (4): Linear(in_features=20, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch 1-------------------------------\n",
      "Training loss: 76724.544921875\n",
      "Test loss: 75011.992188 \n",
      "\n",
      "Epoch 2-------------------------------\n",
      "Training loss: 76706.284765625\n",
      "Test loss: 75001.890625 \n",
      "\n",
      "Epoch 3-------------------------------\n",
      "Training loss: 76686.3091796875\n",
      "Test loss: 74990.750000 \n",
      "\n",
      "Epoch 4-------------------------------\n",
      "Training loss: 76663.801171875\n",
      "Test loss: 74978.289062 \n",
      "\n",
      "Epoch 5-------------------------------\n",
      "Training loss: 76638.4681640625\n",
      "Test loss: 74964.257812 \n",
      "\n",
      "Epoch 6-------------------------------\n",
      "Training loss: 76609.577734375\n",
      "Test loss: 74948.453125 \n",
      "\n",
      "Epoch 7-------------------------------\n",
      "Training loss: 76577.2583984375\n",
      "Test loss: 74930.710938 \n",
      "\n",
      "Epoch 8-------------------------------\n",
      "Training loss: 76540.627734375\n",
      "Test loss: 74911.046875 \n",
      "\n",
      "Epoch 9-------------------------------\n",
      "Training loss: 76499.772265625\n",
      "Test loss: 74889.429688 \n",
      "\n",
      "Epoch 10-------------------------------\n",
      "Training loss: 76455.4763671875\n",
      "Test loss: 74866.453125 \n",
      "\n",
      "Epoch 11-------------------------------\n",
      "Training loss: 76407.7859375\n",
      "Test loss: 74842.171875 \n",
      "\n",
      "Epoch 12-------------------------------\n",
      "Training loss: 76357.3705078125\n",
      "Test loss: 74817.234375 \n",
      "\n",
      "Epoch 13-------------------------------\n",
      "Training loss: 76305.12578125\n",
      "Test loss: 74791.882812 \n",
      "\n",
      "Epoch 14-------------------------------\n",
      "Training loss: 76251.476953125\n",
      "Test loss: 74766.875000 \n",
      "\n",
      "Epoch 15-------------------------------\n",
      "Training loss: 76197.6041015625\n",
      "Test loss: 74742.453125 \n",
      "\n",
      "Epoch 16-------------------------------\n",
      "Training loss: 76144.021484375\n",
      "Test loss: 74719.062500 \n",
      "\n",
      "Epoch 17-------------------------------\n",
      "Training loss: 76091.994921875\n",
      "Test loss: 74697.007812 \n",
      "\n",
      "Epoch 18-------------------------------\n",
      "Training loss: 76040.1076171875\n",
      "Test loss: 74676.445312 \n",
      "\n",
      "Epoch 19-------------------------------\n",
      "Training loss: 75990.8724609375\n",
      "Test loss: 74657.390625 \n",
      "\n",
      "Epoch 20-------------------------------\n",
      "Training loss: 75942.941015625\n",
      "Test loss: 74640.156250 \n",
      "\n",
      "Epoch 21-------------------------------\n",
      "Training loss: 75896.78125\n",
      "Test loss: 74624.507812 \n",
      "\n",
      "Epoch 22-------------------------------\n",
      "Training loss: 75852.996875\n",
      "Test loss: 74610.585938 \n",
      "\n",
      "Epoch 23-------------------------------\n",
      "Training loss: 75811.0595703125\n",
      "Test loss: 74598.335938 \n",
      "\n",
      "Epoch 24-------------------------------\n",
      "Training loss: 75770.521484375\n",
      "Test loss: 74587.648438 \n",
      "\n",
      "Epoch 25-------------------------------\n",
      "Training loss: 75731.5822265625\n",
      "Test loss: 74578.492188 \n",
      "\n",
      "Epoch 26-------------------------------\n",
      "Training loss: 75693.8849609375\n",
      "Test loss: 74570.726562 \n",
      "\n",
      "Epoch 27-------------------------------\n",
      "Training loss: 75655.4296875\n",
      "Test loss: 74564.484375 \n",
      "\n",
      "Epoch 28-------------------------------\n",
      "Training loss: 75614.74140625\n",
      "Test loss: 74559.859375 \n",
      "\n",
      "Epoch 29-------------------------------\n",
      "Training loss: 75570.4298828125\n",
      "Test loss: 74557.171875 \n",
      "\n",
      "Epoch 30-------------------------------\n",
      "Training loss: 75506.096484375\n",
      "Test loss: 74558.820312 \n",
      "\n",
      "Epoch 31-------------------------------\n",
      "Training loss: 75373.382421875\n",
      "Test loss: 74580.390625 \n",
      "\n",
      "Epoch 32-------------------------------\n",
      "Training loss: 74983.5365234375\n",
      "Test loss: 74662.992188 \n",
      "\n",
      "Epoch 33-------------------------------\n",
      "Training loss: 73860.3740234375\n",
      "Test loss: 75062.031250 \n",
      "\n",
      "Epoch 34-------------------------------\n",
      "Training loss: 71392.79755859375\n",
      "Test loss: 75223.640625 \n",
      "\n",
      "Epoch 35-------------------------------\n",
      "Training loss: 68403.19599609375\n",
      "Test loss: 76304.960938 \n",
      "\n",
      "Epoch 36-------------------------------\n",
      "Training loss: 66864.631640625\n",
      "Test loss: 76554.843750 \n",
      "\n",
      "Epoch 37-------------------------------\n",
      "Training loss: 65520.4224609375\n",
      "Test loss: 76157.039062 \n",
      "\n",
      "Epoch 38-------------------------------\n",
      "Training loss: 63746.6923828125\n",
      "Test loss: 77760.007812 \n",
      "\n",
      "Epoch 39-------------------------------\n",
      "Training loss: 60913.46494140625\n",
      "Test loss: 76974.625000 \n",
      "\n",
      "Epoch 40-------------------------------\n",
      "Training loss: 63462.22275390625\n",
      "Test loss: 77302.132812 \n",
      "\n",
      "Epoch 41-------------------------------\n",
      "Training loss: 58859.314453125\n",
      "Test loss: 79507.406250 \n",
      "\n",
      "Epoch 42-------------------------------\n",
      "Training loss: 58627.6779296875\n",
      "Test loss: 78258.523438 \n",
      "\n",
      "Epoch 43-------------------------------\n",
      "Training loss: 58130.31904296875\n",
      "Test loss: 79294.156250 \n",
      "\n",
      "Epoch 44-------------------------------\n",
      "Training loss: 60069.0548828125\n",
      "Test loss: 80489.593750 \n",
      "\n",
      "Epoch 45-------------------------------\n",
      "Training loss: 56387.18251953125\n",
      "Test loss: 80936.703125 \n",
      "\n",
      "Epoch 46-------------------------------\n",
      "Training loss: 52373.7369140625\n",
      "Test loss: 76910.437500 \n",
      "\n",
      "Epoch 47-------------------------------\n",
      "Training loss: 51984.76611328125\n",
      "Test loss: 82006.593750 \n",
      "\n",
      "Epoch 48-------------------------------\n",
      "Training loss: 50455.45693359375\n",
      "Test loss: 81730.476562 \n",
      "\n",
      "Epoch 49-------------------------------\n",
      "Training loss: 52522.07451171875\n",
      "Test loss: 81665.546875 \n",
      "\n",
      "Epoch 50-------------------------------\n",
      "Training loss: 47587.09326171875\n",
      "Test loss: 79534.539062 \n",
      "\n",
      "Epoch 51-------------------------------\n",
      "Training loss: 50817.53046875\n",
      "Test loss: 78991.671875 \n",
      "\n",
      "Epoch 52-------------------------------\n",
      "Training loss: 48314.41645507813\n",
      "Test loss: 83475.968750 \n",
      "\n",
      "Epoch 53-------------------------------\n",
      "Training loss: 44383.923583984375\n",
      "Test loss: 85287.476562 \n",
      "\n",
      "Epoch 54-------------------------------\n",
      "Training loss: 49873.59809570313\n",
      "Test loss: 85332.820312 \n",
      "\n",
      "Epoch 55-------------------------------\n",
      "Training loss: 44735.59243164062\n",
      "Test loss: 87211.296875 \n",
      "\n",
      "Epoch 56-------------------------------\n",
      "Training loss: 43005.10063476562\n",
      "Test loss: 88430.601562 \n",
      "\n",
      "Epoch 57-------------------------------\n",
      "Training loss: 40388.313232421875\n",
      "Test loss: 87146.046875 \n",
      "\n",
      "Epoch 58-------------------------------\n",
      "Training loss: 40270.22490234375\n",
      "Test loss: 88725.156250 \n",
      "\n",
      "Epoch 59-------------------------------\n",
      "Training loss: 39581.126953125\n",
      "Test loss: 87094.101562 \n",
      "\n",
      "Epoch 60-------------------------------\n",
      "Training loss: 46989.58642578125\n",
      "Test loss: 85165.601562 \n",
      "\n",
      "Epoch 61-------------------------------\n",
      "Training loss: 57204.22265625\n",
      "Test loss: 90483.460938 \n",
      "\n",
      "Epoch 62-------------------------------\n",
      "Training loss: 72176.1341796875\n",
      "Test loss: 84993.812500 \n",
      "\n",
      "Epoch 63-------------------------------\n",
      "Training loss: 57241.201953125\n",
      "Test loss: 87024.039062 \n",
      "\n",
      "Epoch 64-------------------------------\n",
      "Training loss: 42133.552978515625\n",
      "Test loss: 90685.578125 \n",
      "\n",
      "Epoch 65-------------------------------\n",
      "Training loss: 35606.88046875\n",
      "Test loss: 91668.500000 \n",
      "\n",
      "Epoch 66-------------------------------\n",
      "Training loss: 36411.487890625\n",
      "Test loss: 93885.476562 \n",
      "\n",
      "Epoch 67-------------------------------\n",
      "Training loss: 34964.156494140625\n",
      "Test loss: 93354.953125 \n",
      "\n",
      "Epoch 68-------------------------------\n",
      "Training loss: 32039.98720703125\n",
      "Test loss: 92582.117188 \n",
      "\n",
      "Epoch 69-------------------------------\n",
      "Training loss: 32981.615234375\n",
      "Test loss: 95005.296875 \n",
      "\n",
      "Epoch 70-------------------------------\n",
      "Training loss: 38204.45888671875\n",
      "Test loss: 96278.820312 \n",
      "\n",
      "Epoch 71-------------------------------\n",
      "Training loss: 35985.83823242188\n",
      "Test loss: 96829.695312 \n",
      "\n",
      "Epoch 72-------------------------------\n",
      "Training loss: 31896.42038574219\n",
      "Test loss: 96607.320312 \n",
      "\n",
      "Epoch 73-------------------------------\n",
      "Training loss: 35130.09677734375\n",
      "Test loss: 95428.656250 \n",
      "\n",
      "Epoch 74-------------------------------\n",
      "Training loss: 31732.72609863281\n",
      "Test loss: 98106.054688 \n",
      "\n",
      "Epoch 75-------------------------------\n",
      "Training loss: 28712.747607421876\n",
      "Test loss: 99928.890625 \n",
      "\n",
      "Epoch 76-------------------------------\n",
      "Training loss: 30402.96730957031\n",
      "Test loss: 100003.906250 \n",
      "\n",
      "Epoch 77-------------------------------\n",
      "Training loss: 42218.71838378906\n",
      "Test loss: 94037.015625 \n",
      "\n",
      "Epoch 78-------------------------------\n",
      "Training loss: 70868.42233886718\n",
      "Test loss: 100872.187500 \n",
      "\n",
      "Epoch 79-------------------------------\n",
      "Training loss: 27351.14812011719\n",
      "Test loss: 100536.601562 \n",
      "\n",
      "Epoch 80-------------------------------\n",
      "Training loss: 31199.26853027344\n",
      "Test loss: 101340.257812 \n",
      "\n",
      "Epoch 81-------------------------------\n",
      "Training loss: 28055.523999023437\n",
      "Test loss: 101966.718750 \n",
      "\n",
      "Epoch 82-------------------------------\n",
      "Training loss: 27521.63347167969\n",
      "Test loss: 102694.367188 \n",
      "\n",
      "Epoch 83-------------------------------\n",
      "Training loss: 25710.39406738281\n",
      "Test loss: 103249.101562 \n",
      "\n",
      "Epoch 84-------------------------------\n",
      "Training loss: 28814.40947265625\n",
      "Test loss: 103791.992188 \n",
      "\n",
      "Epoch 85-------------------------------\n",
      "Training loss: 24806.41555175781\n",
      "Test loss: 103418.578125 \n",
      "\n",
      "Epoch 86-------------------------------\n",
      "Training loss: 25029.127368164063\n",
      "Test loss: 105174.132812 \n",
      "\n",
      "Epoch 87-------------------------------\n",
      "Training loss: 30325.560620117187\n",
      "Test loss: 106778.976562 \n",
      "\n",
      "Epoch 88-------------------------------\n",
      "Training loss: 22465.640478515626\n",
      "Test loss: 107955.789062 \n",
      "\n",
      "Epoch 89-------------------------------\n",
      "Training loss: 25283.328466796876\n",
      "Test loss: 107007.421875 \n",
      "\n",
      "Epoch 90-------------------------------\n",
      "Training loss: 24893.320764160155\n",
      "Test loss: 107153.609375 \n",
      "\n",
      "Epoch 91-------------------------------\n",
      "Training loss: 20430.9390625\n",
      "Test loss: 108426.468750 \n",
      "\n",
      "Epoch 92-------------------------------\n",
      "Training loss: 19336.5826171875\n",
      "Test loss: 108793.187500 \n",
      "\n",
      "Epoch 93-------------------------------\n",
      "Training loss: 18057.207666015624\n",
      "Test loss: 104752.562500 \n",
      "\n",
      "Epoch 94-------------------------------\n",
      "Training loss: 20169.816735839842\n",
      "Test loss: 110937.664062 \n",
      "\n",
      "Epoch 95-------------------------------\n",
      "Training loss: 24948.239306640626\n",
      "Test loss: 111315.812500 \n",
      "\n",
      "Epoch 96-------------------------------\n",
      "Training loss: 16700.88332519531\n",
      "Test loss: 110077.679688 \n",
      "\n",
      "Epoch 97-------------------------------\n",
      "Training loss: 17119.148828125\n",
      "Test loss: 113704.046875 \n",
      "\n",
      "Epoch 98-------------------------------\n",
      "Training loss: 21414.586511230467\n",
      "Test loss: 112171.437500 \n",
      "\n",
      "Epoch 99-------------------------------\n",
      "Training loss: 18666.884545898436\n",
      "Test loss: 113433.164062 \n",
      "\n",
      "Epoch 100-------------------------------\n",
      "Training loss: 21942.716833496095\n",
      "Test loss: 113670.859375 \n",
      "\n",
      "Epoch 101-------------------------------\n",
      "Training loss: 19930.47236328125\n",
      "Test loss: 115276.914062 \n",
      "\n",
      "Epoch 102-------------------------------\n",
      "Training loss: 18054.759423828124\n",
      "Test loss: 115878.898438 \n",
      "\n",
      "Epoch 103-------------------------------\n",
      "Training loss: 17809.392224121093\n",
      "Test loss: 114749.054688 \n",
      "\n",
      "Epoch 104-------------------------------\n",
      "Training loss: 14973.157946777344\n",
      "Test loss: 116231.117188 \n",
      "\n",
      "Epoch 105-------------------------------\n",
      "Training loss: 16628.381384277345\n",
      "Test loss: 115654.093750 \n",
      "\n",
      "Epoch 106-------------------------------\n",
      "Training loss: 13016.459680175782\n",
      "Test loss: 118353.875000 \n",
      "\n",
      "Epoch 107-------------------------------\n",
      "Training loss: 12749.65284423828\n",
      "Test loss: 118742.218750 \n",
      "\n",
      "Epoch 108-------------------------------\n",
      "Training loss: 26165.74704589844\n",
      "Test loss: 118041.242188 \n",
      "\n",
      "Epoch 109-------------------------------\n",
      "Training loss: 11143.595861816406\n",
      "Test loss: 118853.203125 \n",
      "\n",
      "Epoch 110-------------------------------\n",
      "Training loss: 12279.894720458984\n",
      "Test loss: 121023.718750 \n",
      "\n",
      "Epoch 111-------------------------------\n",
      "Training loss: 18318.880712890626\n",
      "Test loss: 120118.796875 \n",
      "\n",
      "Epoch 112-------------------------------\n",
      "Training loss: 12821.651275634766\n",
      "Test loss: 108931.414062 \n",
      "\n",
      "Epoch 113-------------------------------\n",
      "Training loss: 12903.122326660156\n",
      "Test loss: 122399.164062 \n",
      "\n",
      "Epoch 114-------------------------------\n",
      "Training loss: 11405.941522216797\n",
      "Test loss: 121471.398438 \n",
      "\n",
      "Epoch 115-------------------------------\n",
      "Training loss: 16090.240753173828\n",
      "Test loss: 120417.070312 \n",
      "\n",
      "Epoch 116-------------------------------\n",
      "Training loss: 16679.726470947266\n",
      "Test loss: 119092.656250 \n",
      "\n",
      "Epoch 117-------------------------------\n",
      "Training loss: 15269.302404785156\n",
      "Test loss: 119898.015625 \n",
      "\n",
      "Epoch 118-------------------------------\n",
      "Training loss: 8604.59833984375\n",
      "Test loss: 112722.773438 \n",
      "\n",
      "Epoch 119-------------------------------\n",
      "Training loss: 14648.812030029298\n",
      "Test loss: 125609.992188 \n",
      "\n",
      "Epoch 120-------------------------------\n",
      "Training loss: 16182.22036743164\n",
      "Test loss: 124093.742188 \n",
      "\n",
      "Epoch 121-------------------------------\n",
      "Training loss: 11382.190747070312\n",
      "Test loss: 126409.406250 \n",
      "\n",
      "Epoch 122-------------------------------\n",
      "Training loss: 14067.934631347656\n",
      "Test loss: 122721.085938 \n",
      "\n",
      "Epoch 123-------------------------------\n",
      "Training loss: 11739.486364746093\n",
      "Test loss: 127462.203125 \n",
      "\n",
      "Epoch 124-------------------------------\n",
      "Training loss: 14233.015432739257\n",
      "Test loss: 121890.750000 \n",
      "\n",
      "Epoch 125-------------------------------\n",
      "Training loss: 10935.252770996094\n",
      "Test loss: 117870.140625 \n",
      "\n",
      "Epoch 126-------------------------------\n",
      "Training loss: 14933.370623779298\n",
      "Test loss: 122652.195312 \n",
      "\n",
      "Epoch 127-------------------------------\n",
      "Training loss: 12097.94955444336\n",
      "Test loss: 128832.843750 \n",
      "\n",
      "Epoch 128-------------------------------\n",
      "Training loss: 13207.473840332032\n",
      "Test loss: 128620.218750 \n",
      "\n",
      "Epoch 129-------------------------------\n",
      "Training loss: 6879.379406738281\n",
      "Test loss: 129693.476562 \n",
      "\n",
      "Epoch 130-------------------------------\n",
      "Training loss: 11304.601867675781\n",
      "Test loss: 125170.835938 \n",
      "\n",
      "Epoch 131-------------------------------\n",
      "Training loss: 11885.807928466797\n",
      "Test loss: 128860.492188 \n",
      "\n",
      "Epoch 132-------------------------------\n",
      "Training loss: 7172.52705078125\n",
      "Test loss: 130204.132812 \n",
      "\n",
      "Epoch 133-------------------------------\n",
      "Training loss: 10577.530398559571\n",
      "Test loss: 131240.015625 \n",
      "\n",
      "Epoch 134-------------------------------\n",
      "Training loss: 11825.12919921875\n",
      "Test loss: 131302.109375 \n",
      "\n",
      "Epoch 135-------------------------------\n",
      "Training loss: 9065.812884521485\n",
      "Test loss: 127746.968750 \n",
      "\n",
      "Epoch 136-------------------------------\n",
      "Training loss: 9328.83487548828\n",
      "Test loss: 131685.812500 \n",
      "\n",
      "Epoch 137-------------------------------\n",
      "Training loss: 9887.044873046874\n",
      "Test loss: 132906.500000 \n",
      "\n",
      "Epoch 138-------------------------------\n",
      "Training loss: 12388.831829833984\n",
      "Test loss: 130747.335938 \n",
      "\n",
      "Epoch 139-------------------------------\n",
      "Training loss: 11696.655200195313\n",
      "Test loss: 126997.398438 \n",
      "\n",
      "Epoch 140-------------------------------\n",
      "Training loss: 8042.843743896485\n",
      "Test loss: 126033.945312 \n",
      "\n",
      "Epoch 141-------------------------------\n",
      "Training loss: 12618.061877441407\n",
      "Test loss: 131290.281250 \n",
      "\n",
      "Epoch 142-------------------------------\n",
      "Training loss: 7778.351995849609\n",
      "Test loss: 130160.789062 \n",
      "\n",
      "Epoch 143-------------------------------\n",
      "Training loss: 8847.589846801759\n",
      "Test loss: 132708.562500 \n",
      "\n",
      "Epoch 144-------------------------------\n",
      "Training loss: 10056.064443969726\n",
      "Test loss: 134620.046875 \n",
      "\n",
      "Epoch 145-------------------------------\n",
      "Training loss: 7416.349609375\n",
      "Test loss: 135256.031250 \n",
      "\n",
      "Epoch 146-------------------------------\n",
      "Training loss: 7680.685406494141\n",
      "Test loss: 132013.890625 \n",
      "\n",
      "Epoch 147-------------------------------\n",
      "Training loss: 8039.276580810547\n",
      "Test loss: 130820.601562 \n",
      "\n",
      "Epoch 148-------------------------------\n",
      "Training loss: 11680.64324645996\n",
      "Test loss: 134410.328125 \n",
      "\n",
      "Epoch 149-------------------------------\n",
      "Training loss: 13007.963107299805\n",
      "Test loss: 130127.585938 \n",
      "\n",
      "Epoch 150-------------------------------\n",
      "Training loss: 8437.422631835938\n",
      "Test loss: 131577.484375 \n",
      "\n",
      "Epoch 151-------------------------------\n",
      "Training loss: 9730.12110595703\n",
      "Test loss: 131364.828125 \n",
      "\n",
      "Epoch 152-------------------------------\n",
      "Training loss: 7341.744012451172\n",
      "Test loss: 133137.921875 \n",
      "\n",
      "Epoch 153-------------------------------\n",
      "Training loss: 5082.4692657470705\n",
      "Test loss: 134350.031250 \n",
      "\n",
      "Epoch 154-------------------------------\n",
      "Training loss: 5807.405117797852\n",
      "Test loss: 132388.015625 \n",
      "\n",
      "Epoch 155-------------------------------\n",
      "Training loss: 8600.172497558593\n",
      "Test loss: 133622.500000 \n",
      "\n",
      "Epoch 156-------------------------------\n",
      "Training loss: 7975.62158203125\n",
      "Test loss: 131013.273438 \n",
      "\n",
      "Epoch 157-------------------------------\n",
      "Training loss: 11961.810681152343\n",
      "Test loss: 132675.453125 \n",
      "\n",
      "Epoch 158-------------------------------\n",
      "Training loss: 9541.243716430665\n",
      "Test loss: 133373.812500 \n",
      "\n",
      "Epoch 159-------------------------------\n",
      "Training loss: 15397.57551574707\n",
      "Test loss: 132988.281250 \n",
      "\n",
      "Epoch 160-------------------------------\n",
      "Training loss: 9081.181744384765\n",
      "Test loss: 132950.828125 \n",
      "\n",
      "Epoch 161-------------------------------\n",
      "Training loss: 7652.6185546875\n",
      "Test loss: 133534.750000 \n",
      "\n",
      "Epoch 162-------------------------------\n",
      "Training loss: 7567.703765869141\n",
      "Test loss: 132335.953125 \n",
      "\n",
      "Epoch 163-------------------------------\n",
      "Training loss: 8206.499975585937\n",
      "Test loss: 134257.843750 \n",
      "\n",
      "Epoch 164-------------------------------\n",
      "Training loss: 6443.935812377929\n",
      "Test loss: 133676.656250 \n",
      "\n",
      "Epoch 165-------------------------------\n",
      "Training loss: 5350.945834350586\n",
      "Test loss: 135020.593750 \n",
      "\n",
      "Epoch 166-------------------------------\n",
      "Training loss: 10202.291223144532\n",
      "Test loss: 131375.984375 \n",
      "\n",
      "Epoch 167-------------------------------\n",
      "Training loss: 7737.499432373047\n",
      "Test loss: 135359.000000 \n",
      "\n",
      "Epoch 168-------------------------------\n",
      "Training loss: 9375.083944702148\n",
      "Test loss: 127160.625000 \n",
      "\n",
      "Epoch 169-------------------------------\n",
      "Training loss: 7133.3176544189455\n",
      "Test loss: 131300.828125 \n",
      "\n",
      "Epoch 170-------------------------------\n",
      "Training loss: 6916.235110473633\n",
      "Test loss: 136096.437500 \n",
      "\n",
      "Epoch 171-------------------------------\n",
      "Training loss: 5261.698815917969\n",
      "Test loss: 136609.453125 \n",
      "\n",
      "Epoch 172-------------------------------\n",
      "Training loss: 6240.154193115234\n",
      "Test loss: 136708.765625 \n",
      "\n",
      "Epoch 173-------------------------------\n",
      "Training loss: 6743.342251586914\n",
      "Test loss: 136145.718750 \n",
      "\n",
      "Epoch 174-------------------------------\n",
      "Training loss: 19816.943826293944\n",
      "Test loss: 136169.812500 \n",
      "\n",
      "Epoch 175-------------------------------\n",
      "Training loss: 4504.422782897949\n",
      "Test loss: 134212.734375 \n",
      "\n",
      "Epoch 176-------------------------------\n",
      "Training loss: 8705.508113098145\n",
      "Test loss: 137063.515625 \n",
      "\n",
      "Epoch 177-------------------------------\n",
      "Training loss: 9402.218237304687\n",
      "Test loss: 135896.187500 \n",
      "\n",
      "Epoch 178-------------------------------\n",
      "Training loss: 6373.283042907715\n",
      "Test loss: 136452.171875 \n",
      "\n",
      "Epoch 179-------------------------------\n",
      "Training loss: 6307.274192810059\n",
      "Test loss: 137569.406250 \n",
      "\n",
      "Epoch 180-------------------------------\n",
      "Training loss: 9959.073356628418\n",
      "Test loss: 136534.406250 \n",
      "\n",
      "Epoch 181-------------------------------\n",
      "Training loss: 4261.448278808593\n",
      "Test loss: 135632.515625 \n",
      "\n",
      "Epoch 182-------------------------------\n",
      "Training loss: 6098.369323730469\n",
      "Test loss: 134241.609375 \n",
      "\n",
      "Epoch 183-------------------------------\n",
      "Training loss: 7946.746002197266\n",
      "Test loss: 138609.343750 \n",
      "\n",
      "Epoch 184-------------------------------\n",
      "Training loss: 10900.548962402343\n",
      "Test loss: 135388.296875 \n",
      "\n",
      "Epoch 185-------------------------------\n",
      "Training loss: 6879.330619812012\n",
      "Test loss: 138096.843750 \n",
      "\n",
      "Epoch 186-------------------------------\n",
      "Training loss: 8234.296298217774\n",
      "Test loss: 138276.765625 \n",
      "\n",
      "Epoch 187-------------------------------\n",
      "Training loss: 5833.086212158203\n",
      "Test loss: 137498.015625 \n",
      "\n",
      "Epoch 188-------------------------------\n",
      "Training loss: 7829.886531066894\n",
      "Test loss: 138683.828125 \n",
      "\n",
      "Epoch 189-------------------------------\n",
      "Training loss: 8848.88592376709\n",
      "Test loss: 138055.093750 \n",
      "\n",
      "Epoch 190-------------------------------\n",
      "Training loss: 5737.156756591797\n",
      "Test loss: 139547.593750 \n",
      "\n",
      "Epoch 191-------------------------------\n",
      "Training loss: 8598.95191040039\n",
      "Test loss: 133899.812500 \n",
      "\n",
      "Epoch 192-------------------------------\n",
      "Training loss: 4534.320874023438\n",
      "Test loss: 138969.609375 \n",
      "\n",
      "Epoch 193-------------------------------\n",
      "Training loss: 6234.539193725586\n",
      "Test loss: 139599.671875 \n",
      "\n",
      "Epoch 194-------------------------------\n",
      "Training loss: 6437.750093078614\n",
      "Test loss: 139939.531250 \n",
      "\n",
      "Epoch 195-------------------------------\n",
      "Training loss: 7274.366903686523\n",
      "Test loss: 139879.421875 \n",
      "\n",
      "Epoch 196-------------------------------\n",
      "Training loss: 9262.654718017578\n",
      "Test loss: 136118.312500 \n",
      "\n",
      "Epoch 197-------------------------------\n",
      "Training loss: 3107.422183227539\n",
      "Test loss: 138857.921875 \n",
      "\n",
      "Epoch 198-------------------------------\n",
      "Training loss: 10524.250741577149\n",
      "Test loss: 134860.187500 \n",
      "\n",
      "Epoch 199-------------------------------\n",
      "Training loss: 7607.664605712891\n",
      "Test loss: 138188.546875 \n",
      "\n",
      "Epoch 200-------------------------------\n",
      "Training loss: 6338.529859924316\n",
      "Test loss: 138134.406250 \n",
      "\n",
      "Epoch 201-------------------------------\n",
      "Training loss: 3759.2886016845705\n",
      "Test loss: 135802.687500 \n",
      "\n",
      "Epoch 202-------------------------------\n",
      "Training loss: 6704.47579498291\n",
      "Test loss: 138446.968750 \n",
      "\n",
      "Epoch 203-------------------------------\n",
      "Training loss: 2943.1339721679688\n",
      "Test loss: 141479.031250 \n",
      "\n",
      "Epoch 204-------------------------------\n",
      "Training loss: 7446.972229003906\n",
      "Test loss: 139171.703125 \n",
      "\n",
      "Epoch 205-------------------------------\n",
      "Training loss: 5015.162855529785\n",
      "Test loss: 134338.406250 \n",
      "\n",
      "Epoch 206-------------------------------\n",
      "Training loss: 6525.8350280761715\n",
      "Test loss: 138598.187500 \n",
      "\n",
      "Epoch 207-------------------------------\n",
      "Training loss: 7552.561752319336\n",
      "Test loss: 137228.015625 \n",
      "\n",
      "Epoch 208-------------------------------\n",
      "Training loss: 7863.355767822266\n",
      "Test loss: 132242.531250 \n",
      "\n",
      "Epoch 209-------------------------------\n",
      "Training loss: 8485.578967285157\n",
      "Test loss: 136365.968750 \n",
      "\n",
      "Epoch 210-------------------------------\n",
      "Training loss: 7285.262419128418\n",
      "Test loss: 134036.546875 \n",
      "\n",
      "Epoch 211-------------------------------\n",
      "Training loss: 4557.372100830078\n",
      "Test loss: 140599.703125 \n",
      "\n",
      "Epoch 212-------------------------------\n",
      "Training loss: 8137.146728515625\n",
      "Test loss: 138391.062500 \n",
      "\n",
      "Epoch 213-------------------------------\n",
      "Training loss: 4243.000607299805\n",
      "Test loss: 139420.843750 \n",
      "\n",
      "Epoch 214-------------------------------\n",
      "Training loss: 5332.202645874024\n",
      "Test loss: 138593.156250 \n",
      "\n",
      "Epoch 215-------------------------------\n",
      "Training loss: 4058.2112731933594\n",
      "Test loss: 140569.281250 \n",
      "\n",
      "Epoch 216-------------------------------\n",
      "Training loss: 6457.696612548828\n",
      "Test loss: 137084.015625 \n",
      "\n",
      "Epoch 217-------------------------------\n",
      "Training loss: 6145.508578491211\n",
      "Test loss: 136857.281250 \n",
      "\n",
      "Epoch 218-------------------------------\n",
      "Training loss: 5793.491494750977\n",
      "Test loss: 139918.875000 \n",
      "\n",
      "Epoch 219-------------------------------\n",
      "Training loss: 3535.3216690063477\n",
      "Test loss: 140901.500000 \n",
      "\n",
      "Epoch 220-------------------------------\n",
      "Training loss: 4023.8334533691404\n",
      "Test loss: 140800.171875 \n",
      "\n",
      "Epoch 221-------------------------------\n",
      "Training loss: 8470.717750549316\n",
      "Test loss: 138280.703125 \n",
      "\n",
      "Epoch 222-------------------------------\n",
      "Training loss: 3426.894122314453\n",
      "Test loss: 139650.515625 \n",
      "\n",
      "Epoch 223-------------------------------\n",
      "Training loss: 4030.6220703125\n",
      "Test loss: 140837.531250 \n",
      "\n",
      "Epoch 224-------------------------------\n",
      "Training loss: 9187.897358703613\n",
      "Test loss: 138962.562500 \n",
      "\n",
      "Epoch 225-------------------------------\n",
      "Training loss: 4388.892565917969\n",
      "Test loss: 134668.078125 \n",
      "\n",
      "Epoch 226-------------------------------\n",
      "Training loss: 7843.0648941040035\n",
      "Test loss: 140014.093750 \n",
      "\n",
      "Epoch 227-------------------------------\n",
      "Training loss: 8386.718769836425\n",
      "Test loss: 137070.593750 \n",
      "\n",
      "Epoch 228-------------------------------\n",
      "Training loss: 4188.071501159668\n",
      "Test loss: 139115.625000 \n",
      "\n",
      "Epoch 229-------------------------------\n",
      "Training loss: 7545.830621337891\n",
      "Test loss: 138235.718750 \n",
      "\n",
      "Epoch 230-------------------------------\n",
      "Training loss: 4826.380601501465\n",
      "Test loss: 140038.437500 \n",
      "\n",
      "Epoch 231-------------------------------\n",
      "Training loss: 4772.102931976318\n",
      "Test loss: 141073.296875 \n",
      "\n",
      "Epoch 232-------------------------------\n",
      "Training loss: 5665.724552917481\n",
      "Test loss: 138717.812500 \n",
      "\n",
      "Epoch 233-------------------------------\n",
      "Training loss: 6908.236444091797\n",
      "Test loss: 139559.875000 \n",
      "\n",
      "Epoch 234-------------------------------\n",
      "Training loss: 5423.359142303467\n",
      "Test loss: 140270.609375 \n",
      "\n",
      "Epoch 235-------------------------------\n",
      "Training loss: 3136.6932487487793\n",
      "Test loss: 142044.515625 \n",
      "\n",
      "Epoch 236-------------------------------\n",
      "Training loss: 8784.712477111816\n",
      "Test loss: 138805.906250 \n",
      "\n",
      "Epoch 237-------------------------------\n",
      "Training loss: 4935.843041992188\n",
      "Test loss: 140896.031250 \n",
      "\n",
      "Epoch 238-------------------------------\n",
      "Training loss: 5520.02494354248\n",
      "Test loss: 140366.546875 \n",
      "\n",
      "Epoch 239-------------------------------\n",
      "Training loss: 2227.421810913086\n",
      "Test loss: 142009.718750 \n",
      "\n",
      "Epoch 240-------------------------------\n",
      "Training loss: 6302.446360778808\n",
      "Test loss: 137746.062500 \n",
      "\n",
      "Epoch 241-------------------------------\n",
      "Training loss: 5234.606324768067\n",
      "Test loss: 139416.312500 \n",
      "\n",
      "Epoch 242-------------------------------\n",
      "Training loss: 5475.957137298584\n",
      "Test loss: 140369.078125 \n",
      "\n",
      "Epoch 243-------------------------------\n",
      "Training loss: 6617.778775024414\n",
      "Test loss: 140472.140625 \n",
      "\n",
      "Epoch 244-------------------------------\n",
      "Training loss: 6033.693574523926\n",
      "Test loss: 141171.843750 \n",
      "\n",
      "Epoch 245-------------------------------\n",
      "Training loss: 6701.206494140625\n",
      "Test loss: 139798.359375 \n",
      "\n",
      "Epoch 246-------------------------------\n",
      "Training loss: 3632.222981262207\n",
      "Test loss: 143052.609375 \n",
      "\n",
      "Epoch 247-------------------------------\n",
      "Training loss: 4225.114022064209\n",
      "Test loss: 142495.031250 \n",
      "\n",
      "Epoch 248-------------------------------\n",
      "Training loss: 12567.997813415528\n",
      "Test loss: 139537.484375 \n",
      "\n",
      "Epoch 249-------------------------------\n",
      "Training loss: 3220.879133605957\n",
      "Test loss: 140933.078125 \n",
      "\n",
      "Epoch 250-------------------------------\n",
      "Training loss: 7634.6162033081055\n",
      "Test loss: 138858.218750 \n",
      "\n",
      "Epoch 251-------------------------------\n",
      "Training loss: 4347.8935821533205\n",
      "Test loss: 139634.828125 \n",
      "\n",
      "Epoch 252-------------------------------\n",
      "Training loss: 5140.482988739013\n",
      "Test loss: 141411.203125 \n",
      "\n",
      "Epoch 253-------------------------------\n",
      "Training loss: 4091.0389961242677\n",
      "Test loss: 143280.046875 \n",
      "\n",
      "Epoch 254-------------------------------\n",
      "Training loss: 6945.058590698242\n",
      "Test loss: 140601.234375 \n",
      "\n",
      "Epoch 255-------------------------------\n",
      "Training loss: 9282.702093505859\n",
      "Test loss: 140275.765625 \n",
      "\n",
      "Epoch 256-------------------------------\n",
      "Training loss: 3288.8580932617188\n",
      "Test loss: 140983.234375 \n",
      "\n",
      "Epoch 257-------------------------------\n",
      "Training loss: 5540.993688964843\n",
      "Test loss: 141403.343750 \n",
      "\n",
      "Epoch 258-------------------------------\n",
      "Training loss: 2867.662680053711\n",
      "Test loss: 143218.734375 \n",
      "\n",
      "Epoch 259-------------------------------\n",
      "Training loss: 4520.419326019287\n",
      "Test loss: 141731.046875 \n",
      "\n",
      "Epoch 260-------------------------------\n",
      "Training loss: 5058.038279724121\n",
      "Test loss: 140198.593750 \n",
      "\n",
      "Epoch 261-------------------------------\n",
      "Training loss: 4424.4586532592775\n",
      "Test loss: 142819.562500 \n",
      "\n",
      "Epoch 262-------------------------------\n",
      "Training loss: 7362.484098815918\n",
      "Test loss: 140831.515625 \n",
      "\n",
      "Epoch 263-------------------------------\n",
      "Training loss: 5283.781057739257\n",
      "Test loss: 141950.453125 \n",
      "\n",
      "Epoch 264-------------------------------\n",
      "Training loss: 4842.394661712647\n",
      "Test loss: 143396.093750 \n",
      "\n",
      "Epoch 265-------------------------------\n",
      "Training loss: 1983.8235176086425\n",
      "Test loss: 144640.437500 \n",
      "\n",
      "Epoch 266-------------------------------\n",
      "Training loss: 3811.9487365722657\n",
      "Test loss: 143026.609375 \n",
      "\n",
      "Epoch 267-------------------------------\n",
      "Training loss: 6229.084220123291\n",
      "Test loss: 140339.937500 \n",
      "\n",
      "Epoch 268-------------------------------\n",
      "Training loss: 3105.183760070801\n",
      "Test loss: 144347.968750 \n",
      "\n",
      "Epoch 269-------------------------------\n",
      "Training loss: 2606.176190185547\n",
      "Test loss: 144882.781250 \n",
      "\n",
      "Epoch 270-------------------------------\n",
      "Training loss: 7368.4144088745115\n",
      "Test loss: 141783.781250 \n",
      "\n",
      "Epoch 271-------------------------------\n",
      "Training loss: 5438.4184272766115\n",
      "Test loss: 140155.625000 \n",
      "\n",
      "Epoch 272-------------------------------\n",
      "Training loss: 4916.055289459228\n",
      "Test loss: 143820.671875 \n",
      "\n",
      "Epoch 273-------------------------------\n",
      "Training loss: 3410.2818466186523\n",
      "Test loss: 144849.531250 \n",
      "\n",
      "Epoch 274-------------------------------\n",
      "Training loss: 7199.976625823974\n",
      "Test loss: 141864.187500 \n",
      "\n",
      "Epoch 275-------------------------------\n",
      "Training loss: 3134.7669929504395\n",
      "Test loss: 144200.718750 \n",
      "\n",
      "Epoch 276-------------------------------\n",
      "Training loss: 2612.8608642578124\n",
      "Test loss: 144871.390625 \n",
      "\n",
      "Epoch 277-------------------------------\n",
      "Training loss: 3400.07594833374\n",
      "Test loss: 144112.843750 \n",
      "\n",
      "Epoch 278-------------------------------\n",
      "Training loss: 6815.62712020874\n",
      "Test loss: 142207.171875 \n",
      "\n",
      "Epoch 279-------------------------------\n",
      "Training loss: 4610.197850799561\n",
      "Test loss: 142246.812500 \n",
      "\n",
      "Epoch 280-------------------------------\n",
      "Training loss: 5393.004153442383\n",
      "Test loss: 142912.703125 \n",
      "\n",
      "Epoch 281-------------------------------\n",
      "Training loss: 6002.440484619141\n",
      "Test loss: 138917.640625 \n",
      "\n",
      "Epoch 282-------------------------------\n",
      "Training loss: 3696.561544799805\n",
      "Test loss: 144184.437500 \n",
      "\n",
      "Epoch 283-------------------------------\n",
      "Training loss: 5136.968048858643\n",
      "Test loss: 142705.515625 \n",
      "\n",
      "Epoch 284-------------------------------\n",
      "Training loss: 3321.0790740966795\n",
      "Test loss: 140518.593750 \n",
      "\n",
      "Epoch 285-------------------------------\n",
      "Training loss: 5720.752545928955\n",
      "Test loss: 142809.968750 \n",
      "\n",
      "Epoch 286-------------------------------\n",
      "Training loss: 3727.2020210266114\n",
      "Test loss: 143771.203125 \n",
      "\n",
      "Epoch 287-------------------------------\n",
      "Training loss: 4123.46137008667\n",
      "Test loss: 144779.234375 \n",
      "\n",
      "Epoch 288-------------------------------\n",
      "Training loss: 1978.784471130371\n",
      "Test loss: 143036.187500 \n",
      "\n",
      "Epoch 289-------------------------------\n",
      "Training loss: 2304.8988822937013\n",
      "Test loss: 145297.765625 \n",
      "\n",
      "Epoch 290-------------------------------\n",
      "Training loss: 3328.0025329589844\n",
      "Test loss: 145460.453125 \n",
      "\n",
      "Epoch 291-------------------------------\n",
      "Training loss: 9944.888145446777\n",
      "Test loss: 142030.718750 \n",
      "\n",
      "Epoch 292-------------------------------\n",
      "Training loss: 3208.6497451782225\n",
      "Test loss: 143175.328125 \n",
      "\n",
      "Epoch 293-------------------------------\n",
      "Training loss: 4823.870280456543\n",
      "Test loss: 142596.203125 \n",
      "\n",
      "Epoch 294-------------------------------\n",
      "Training loss: 5794.434093475342\n",
      "Test loss: 142245.671875 \n",
      "\n",
      "Epoch 295-------------------------------\n",
      "Training loss: 5774.803396606445\n",
      "Test loss: 142488.343750 \n",
      "\n",
      "Epoch 296-------------------------------\n",
      "Training loss: 4114.665972137451\n",
      "Test loss: 144027.062500 \n",
      "\n",
      "Epoch 297-------------------------------\n",
      "Training loss: 3088.2718620300293\n",
      "Test loss: 145026.468750 \n",
      "\n",
      "Epoch 298-------------------------------\n",
      "Training loss: 4635.281418609619\n",
      "Test loss: 143820.343750 \n",
      "\n",
      "Epoch 299-------------------------------\n",
      "Training loss: 5325.249919891357\n",
      "Test loss: 144270.453125 \n",
      "\n",
      "Epoch 300-------------------------------\n",
      "Training loss: 4760.996232604981\n",
      "Test loss: 144628.937500 \n",
      "\n",
      "Epoch 301-------------------------------\n",
      "Training loss: 2816.6730995178223\n",
      "Test loss: 145997.593750 \n",
      "\n",
      "Epoch 302-------------------------------\n",
      "Training loss: 7869.610166168213\n",
      "Test loss: 142251.703125 \n",
      "\n",
      "Epoch 303-------------------------------\n",
      "Training loss: 3099.965367889404\n",
      "Test loss: 144606.812500 \n",
      "\n",
      "Epoch 304-------------------------------\n",
      "Training loss: 7133.939740753174\n",
      "Test loss: 143695.000000 \n",
      "\n",
      "Epoch 305-------------------------------\n",
      "Training loss: 6429.199326324463\n",
      "Test loss: 143807.671875 \n",
      "\n",
      "Epoch 306-------------------------------\n",
      "Training loss: 3707.7244827270506\n",
      "Test loss: 143687.296875 \n",
      "\n",
      "Epoch 307-------------------------------\n",
      "Training loss: 4118.017599487304\n",
      "Test loss: 144946.171875 \n",
      "\n",
      "Epoch 308-------------------------------\n",
      "Training loss: 4070.192668914795\n",
      "Test loss: 143329.296875 \n",
      "\n",
      "Epoch 309-------------------------------\n",
      "Training loss: 3432.5481269836428\n",
      "Test loss: 144956.796875 \n",
      "\n",
      "Epoch 310-------------------------------\n",
      "Training loss: 2351.2288856506348\n",
      "Test loss: 145670.484375 \n",
      "\n",
      "Epoch 311-------------------------------\n",
      "Training loss: 3313.126303863525\n",
      "Test loss: 144403.328125 \n",
      "\n",
      "Epoch 312-------------------------------\n",
      "Training loss: 3993.915633392334\n",
      "Test loss: 143895.671875 \n",
      "\n",
      "Epoch 313-------------------------------\n",
      "Training loss: 5421.127138519287\n",
      "Test loss: 140332.359375 \n",
      "\n",
      "Epoch 314-------------------------------\n",
      "Training loss: 5420.909351348877\n",
      "Test loss: 141373.625000 \n",
      "\n",
      "Epoch 315-------------------------------\n",
      "Training loss: 5423.037507629395\n",
      "Test loss: 142250.656250 \n",
      "\n",
      "Epoch 316-------------------------------\n",
      "Training loss: 4881.502518081665\n",
      "Test loss: 143131.000000 \n",
      "\n",
      "Epoch 317-------------------------------\n",
      "Training loss: 4694.788399505615\n",
      "Test loss: 144874.765625 \n",
      "\n",
      "Epoch 318-------------------------------\n",
      "Training loss: 4636.938617706299\n",
      "Test loss: 144946.296875 \n",
      "\n",
      "Epoch 319-------------------------------\n",
      "Training loss: 4221.120516586304\n",
      "Test loss: 144117.546875 \n",
      "\n",
      "Epoch 320-------------------------------\n",
      "Training loss: 7525.567124176026\n",
      "Test loss: 140015.984375 \n",
      "\n",
      "Epoch 321-------------------------------\n",
      "Training loss: 2079.278030014038\n",
      "Test loss: 143401.890625 \n",
      "\n",
      "Epoch 322-------------------------------\n",
      "Training loss: 2953.5635612487795\n",
      "Test loss: 145175.843750 \n",
      "\n",
      "Epoch 323-------------------------------\n",
      "Training loss: 4978.29248046875\n",
      "Test loss: 143937.000000 \n",
      "\n",
      "Epoch 324-------------------------------\n",
      "Training loss: 8423.033889389038\n",
      "Test loss: 135822.750000 \n",
      "\n",
      "Epoch 325-------------------------------\n",
      "Training loss: 2777.579006958008\n",
      "Test loss: 145650.343750 \n",
      "\n",
      "Epoch 326-------------------------------\n",
      "Training loss: 5083.839501190186\n",
      "Test loss: 142167.687500 \n",
      "\n",
      "Epoch 327-------------------------------\n",
      "Training loss: 4087.726739883423\n",
      "Test loss: 143234.203125 \n",
      "\n",
      "Epoch 328-------------------------------\n",
      "Training loss: 6005.403602600098\n",
      "Test loss: 142171.843750 \n",
      "\n",
      "Epoch 329-------------------------------\n",
      "Training loss: 2858.5942260742186\n",
      "Test loss: 145421.750000 \n",
      "\n",
      "Epoch 330-------------------------------\n",
      "Training loss: 4034.615630340576\n",
      "Test loss: 145700.468750 \n",
      "\n",
      "Epoch 331-------------------------------\n",
      "Training loss: 4626.8426174163815\n",
      "Test loss: 144420.390625 \n",
      "\n",
      "Epoch 332-------------------------------\n",
      "Training loss: 3743.358819580078\n",
      "Test loss: 145851.281250 \n",
      "\n",
      "Epoch 333-------------------------------\n",
      "Training loss: 2780.081569671631\n",
      "Test loss: 145121.656250 \n",
      "\n",
      "Epoch 334-------------------------------\n",
      "Training loss: 4399.345666885376\n",
      "Test loss: 143063.406250 \n",
      "\n",
      "Epoch 335-------------------------------\n",
      "Training loss: 4240.2170135498045\n",
      "Test loss: 145262.390625 \n",
      "\n",
      "Epoch 336-------------------------------\n",
      "Training loss: 5293.190004348755\n",
      "Test loss: 144492.765625 \n",
      "\n",
      "Epoch 337-------------------------------\n",
      "Training loss: 2753.8385055541994\n",
      "Test loss: 139326.406250 \n",
      "\n",
      "Epoch 338-------------------------------\n",
      "Training loss: 6746.842580032348\n",
      "Test loss: 145260.859375 \n",
      "\n",
      "Epoch 339-------------------------------\n",
      "Training loss: 2516.309683609009\n",
      "Test loss: 145222.296875 \n",
      "\n",
      "Epoch 340-------------------------------\n",
      "Training loss: 1741.491005706787\n",
      "Test loss: 146150.781250 \n",
      "\n",
      "Epoch 341-------------------------------\n",
      "Training loss: 3711.1677837371826\n",
      "Test loss: 145112.375000 \n",
      "\n",
      "Epoch 342-------------------------------\n",
      "Training loss: 3209.0831649780275\n",
      "Test loss: 138358.890625 \n",
      "\n",
      "Epoch 343-------------------------------\n",
      "Training loss: 7274.4472965240475\n",
      "Test loss: 140784.812500 \n",
      "\n",
      "Epoch 344-------------------------------\n",
      "Training loss: 1854.5466621398925\n",
      "Test loss: 146030.250000 \n",
      "\n",
      "Epoch 345-------------------------------\n",
      "Training loss: 9608.632736206055\n",
      "Test loss: 135899.703125 \n",
      "\n",
      "Epoch 346-------------------------------\n",
      "Training loss: 5075.938151550293\n",
      "Test loss: 143020.406250 \n",
      "\n",
      "Epoch 347-------------------------------\n",
      "Training loss: 3753.050143432617\n",
      "Test loss: 142908.187500 \n",
      "\n",
      "Epoch 348-------------------------------\n",
      "Training loss: 4036.276431274414\n",
      "Test loss: 142165.109375 \n",
      "\n",
      "Epoch 349-------------------------------\n",
      "Training loss: 3364.3330013275145\n",
      "Test loss: 145081.859375 \n",
      "\n",
      "Epoch 350-------------------------------\n",
      "Training loss: 1375.966995048523\n",
      "Test loss: 145727.453125 \n",
      "\n",
      "Epoch 351-------------------------------\n",
      "Training loss: 3331.800397491455\n",
      "Test loss: 145058.140625 \n",
      "\n",
      "Epoch 352-------------------------------\n",
      "Training loss: 3860.560069656372\n",
      "Test loss: 144522.937500 \n",
      "\n",
      "Epoch 353-------------------------------\n",
      "Training loss: 11274.668553924561\n",
      "Test loss: 135767.796875 \n",
      "\n",
      "Epoch 354-------------------------------\n",
      "Training loss: 4787.080529785157\n",
      "Test loss: 141985.437500 \n",
      "\n",
      "Epoch 355-------------------------------\n",
      "Training loss: 4429.712659454346\n",
      "Test loss: 143731.531250 \n",
      "\n",
      "Epoch 356-------------------------------\n",
      "Training loss: 4645.400844573975\n",
      "Test loss: 143882.015625 \n",
      "\n",
      "Epoch 357-------------------------------\n",
      "Training loss: 2530.3776470184325\n",
      "Test loss: 145364.468750 \n",
      "\n",
      "Epoch 358-------------------------------\n",
      "Training loss: 3420.671797180176\n",
      "Test loss: 144164.859375 \n",
      "\n",
      "Epoch 359-------------------------------\n",
      "Training loss: 2043.2777740478516\n",
      "Test loss: 144813.921875 \n",
      "\n",
      "Epoch 360-------------------------------\n",
      "Training loss: 2646.794230270386\n",
      "Test loss: 144502.171875 \n",
      "\n",
      "Epoch 361-------------------------------\n",
      "Training loss: 3152.6210762023925\n",
      "Test loss: 144941.296875 \n",
      "\n",
      "Epoch 362-------------------------------\n",
      "Training loss: 5562.099687576294\n",
      "Test loss: 143560.781250 \n",
      "\n",
      "Epoch 363-------------------------------\n",
      "Training loss: 2841.488812828064\n",
      "Test loss: 145759.265625 \n",
      "\n",
      "Epoch 364-------------------------------\n",
      "Training loss: 3451.929618835449\n",
      "Test loss: 146054.515625 \n",
      "\n",
      "Epoch 365-------------------------------\n",
      "Training loss: 5172.818802642822\n",
      "Test loss: 139760.671875 \n",
      "\n",
      "Epoch 366-------------------------------\n",
      "Training loss: 1816.7932746887207\n",
      "Test loss: 145458.515625 \n",
      "\n",
      "Epoch 367-------------------------------\n",
      "Training loss: 4507.784106445312\n",
      "Test loss: 145416.281250 \n",
      "\n",
      "Epoch 368-------------------------------\n",
      "Training loss: 5568.347951126098\n",
      "Test loss: 144787.515625 \n",
      "\n",
      "Epoch 369-------------------------------\n",
      "Training loss: 2495.783547592163\n",
      "Test loss: 145638.546875 \n",
      "\n",
      "Epoch 370-------------------------------\n",
      "Training loss: 2391.4818798065185\n",
      "Test loss: 142008.343750 \n",
      "\n",
      "Epoch 371-------------------------------\n",
      "Training loss: 2624.7411052703856\n",
      "Test loss: 145826.000000 \n",
      "\n",
      "Epoch 372-------------------------------\n",
      "Training loss: 2631.452111816406\n",
      "Test loss: 140872.593750 \n",
      "\n",
      "Epoch 373-------------------------------\n",
      "Training loss: 5971.6493854522705\n",
      "Test loss: 144080.968750 \n",
      "\n",
      "Epoch 374-------------------------------\n",
      "Training loss: 2801.60378036499\n",
      "Test loss: 143708.656250 \n",
      "\n",
      "Epoch 375-------------------------------\n",
      "Training loss: 5072.692861557007\n",
      "Test loss: 145153.437500 \n",
      "\n",
      "Epoch 376-------------------------------\n",
      "Training loss: 2004.096146774292\n",
      "Test loss: 145286.796875 \n",
      "\n",
      "Epoch 377-------------------------------\n",
      "Training loss: 4399.67474861145\n",
      "Test loss: 144351.375000 \n",
      "\n",
      "Epoch 378-------------------------------\n",
      "Training loss: 3451.8285360336304\n",
      "Test loss: 145246.765625 \n",
      "\n",
      "Epoch 379-------------------------------\n",
      "Training loss: 2714.243881225586\n",
      "Test loss: 145301.250000 \n",
      "\n",
      "Epoch 380-------------------------------\n",
      "Training loss: 2853.412297439575\n",
      "Test loss: 145317.781250 \n",
      "\n",
      "Epoch 381-------------------------------\n",
      "Training loss: 4328.604133987426\n",
      "Test loss: 145694.031250 \n",
      "\n",
      "Epoch 382-------------------------------\n",
      "Training loss: 3645.2846237182616\n",
      "Test loss: 144268.187500 \n",
      "\n",
      "Epoch 383-------------------------------\n",
      "Training loss: 4430.8927947998045\n",
      "Test loss: 143219.984375 \n",
      "\n",
      "Epoch 384-------------------------------\n",
      "Training loss: 2272.1902652740478\n",
      "Test loss: 138331.921875 \n",
      "\n",
      "Epoch 385-------------------------------\n",
      "Training loss: 8344.373305511475\n",
      "Test loss: 138032.734375 \n",
      "\n",
      "Epoch 386-------------------------------\n",
      "Training loss: 4584.6671691894535\n",
      "Test loss: 145395.562500 \n",
      "\n",
      "Epoch 387-------------------------------\n",
      "Training loss: 1745.7442934036255\n",
      "Test loss: 146023.234375 \n",
      "\n",
      "Epoch 388-------------------------------\n",
      "Training loss: 2664.4204120635986\n",
      "Test loss: 143169.000000 \n",
      "\n",
      "Epoch 389-------------------------------\n",
      "Training loss: 4512.690256500244\n",
      "Test loss: 144959.312500 \n",
      "\n",
      "Epoch 390-------------------------------\n",
      "Training loss: 4304.4975894927975\n",
      "Test loss: 144065.578125 \n",
      "\n",
      "Epoch 391-------------------------------\n",
      "Training loss: 3648.8988996505736\n",
      "Test loss: 144423.718750 \n",
      "\n",
      "Epoch 392-------------------------------\n",
      "Training loss: 961.6714599609375\n",
      "Test loss: 145626.812500 \n",
      "\n",
      "Epoch 393-------------------------------\n",
      "Training loss: 4010.338940811157\n",
      "Test loss: 142545.093750 \n",
      "\n",
      "Epoch 394-------------------------------\n",
      "Training loss: 2905.275374984741\n",
      "Test loss: 145650.671875 \n",
      "\n",
      "Epoch 395-------------------------------\n",
      "Training loss: 5858.600524520874\n",
      "Test loss: 145139.343750 \n",
      "\n",
      "Epoch 396-------------------------------\n",
      "Training loss: 4480.608784866333\n",
      "Test loss: 145226.984375 \n",
      "\n",
      "Epoch 397-------------------------------\n",
      "Training loss: 2501.175794792175\n",
      "Test loss: 144567.656250 \n",
      "\n",
      "Epoch 398-------------------------------\n",
      "Training loss: 1961.5066505432128\n",
      "Test loss: 144669.718750 \n",
      "\n",
      "Epoch 399-------------------------------\n",
      "Training loss: 2325.392555427551\n",
      "Test loss: 145639.453125 \n",
      "\n",
      "Epoch 400-------------------------------\n",
      "Training loss: 3195.133727264404\n",
      "Test loss: 145345.468750 \n",
      "\n",
      "Epoch 401-------------------------------\n",
      "Training loss: 3126.32472114563\n",
      "Test loss: 144832.593750 \n",
      "\n",
      "Epoch 402-------------------------------\n",
      "Training loss: 2184.2633859634398\n",
      "Test loss: 145905.265625 \n",
      "\n",
      "Epoch 403-------------------------------\n",
      "Training loss: 4253.058535957336\n",
      "Test loss: 139171.812500 \n",
      "\n",
      "Epoch 404-------------------------------\n",
      "Training loss: 2099.632582473755\n",
      "Test loss: 146118.953125 \n",
      "\n",
      "Epoch 405-------------------------------\n",
      "Training loss: 1772.0538846969605\n",
      "Test loss: 146197.390625 \n",
      "\n",
      "Epoch 406-------------------------------\n",
      "Training loss: 5061.780341339111\n",
      "Test loss: 145381.671875 \n",
      "\n",
      "Epoch 407-------------------------------\n",
      "Training loss: 5546.591923522949\n",
      "Test loss: 142035.625000 \n",
      "\n",
      "Epoch 408-------------------------------\n",
      "Training loss: 2317.6720962524414\n",
      "Test loss: 145242.750000 \n",
      "\n",
      "Epoch 409-------------------------------\n",
      "Training loss: 2767.857346534729\n",
      "Test loss: 145403.125000 \n",
      "\n",
      "Epoch 410-------------------------------\n",
      "Training loss: 3493.1278146743775\n",
      "Test loss: 145085.328125 \n",
      "\n",
      "Epoch 411-------------------------------\n",
      "Training loss: 3574.596616744995\n",
      "Test loss: 146262.546875 \n",
      "\n",
      "Epoch 412-------------------------------\n",
      "Training loss: 1809.3089057922364\n",
      "Test loss: 145802.984375 \n",
      "\n",
      "Epoch 413-------------------------------\n",
      "Training loss: 3986.2651098251345\n",
      "Test loss: 146797.750000 \n",
      "\n",
      "Epoch 414-------------------------------\n",
      "Training loss: 3165.1964708328246\n",
      "Test loss: 145103.171875 \n",
      "\n",
      "Epoch 415-------------------------------\n",
      "Training loss: 3874.350591659546\n",
      "Test loss: 145584.203125 \n",
      "\n",
      "Epoch 416-------------------------------\n",
      "Training loss: 2479.3882444381716\n",
      "Test loss: 145155.781250 \n",
      "\n",
      "Epoch 417-------------------------------\n",
      "Training loss: 2651.6356667518617\n",
      "Test loss: 146544.046875 \n",
      "\n",
      "Epoch 418-------------------------------\n",
      "Training loss: 744.3471610069275\n",
      "Test loss: 146007.562500 \n",
      "\n",
      "Epoch 419-------------------------------\n",
      "Training loss: 4783.137470626831\n",
      "Test loss: 139373.546875 \n",
      "\n",
      "Epoch 420-------------------------------\n",
      "Training loss: 3294.352052497864\n",
      "Test loss: 145166.328125 \n",
      "\n",
      "Epoch 421-------------------------------\n",
      "Training loss: 5794.067918205261\n",
      "Test loss: 144898.406250 \n",
      "\n",
      "Epoch 422-------------------------------\n",
      "Training loss: 2406.5641693115235\n",
      "Test loss: 146034.406250 \n",
      "\n",
      "Epoch 423-------------------------------\n",
      "Training loss: 3105.614748954773\n",
      "Test loss: 145273.828125 \n",
      "\n",
      "Epoch 424-------------------------------\n",
      "Training loss: 1408.122141933441\n",
      "Test loss: 144364.875000 \n",
      "\n",
      "Epoch 425-------------------------------\n",
      "Training loss: 3150.113428688049\n",
      "Test loss: 144052.187500 \n",
      "\n",
      "Epoch 426-------------------------------\n",
      "Training loss: 3541.0411767959595\n",
      "Test loss: 146207.515625 \n",
      "\n",
      "Epoch 427-------------------------------\n",
      "Training loss: 2822.8294933319094\n",
      "Test loss: 146014.765625 \n",
      "\n",
      "Epoch 428-------------------------------\n",
      "Training loss: 3276.8393951416015\n",
      "Test loss: 145895.875000 \n",
      "\n",
      "Epoch 429-------------------------------\n",
      "Training loss: 2153.7663064956664\n",
      "Test loss: 143437.671875 \n",
      "\n",
      "Epoch 430-------------------------------\n",
      "Training loss: 3438.722709083557\n",
      "Test loss: 146492.640625 \n",
      "\n",
      "Epoch 431-------------------------------\n",
      "Training loss: 1917.119341468811\n",
      "Test loss: 146392.718750 \n",
      "\n",
      "Epoch 432-------------------------------\n",
      "Training loss: 2312.1733677864077\n",
      "Test loss: 144805.734375 \n",
      "\n",
      "Epoch 433-------------------------------\n",
      "Training loss: 2107.594712638855\n",
      "Test loss: 145869.343750 \n",
      "\n",
      "Epoch 434-------------------------------\n",
      "Training loss: 3226.767031478882\n",
      "Test loss: 144197.875000 \n",
      "\n",
      "Epoch 435-------------------------------\n",
      "Training loss: 4637.89445400238\n",
      "Test loss: 144181.296875 \n",
      "\n",
      "Epoch 436-------------------------------\n",
      "Training loss: 3338.303271484375\n",
      "Test loss: 143692.359375 \n",
      "\n",
      "Epoch 437-------------------------------\n",
      "Training loss: 2428.6319931030275\n",
      "Test loss: 145580.234375 \n",
      "\n",
      "Epoch 438-------------------------------\n",
      "Training loss: 1995.4006673812867\n",
      "Test loss: 144193.484375 \n",
      "\n",
      "Epoch 439-------------------------------\n",
      "Training loss: 1474.6161756515503\n",
      "Test loss: 145645.406250 \n",
      "\n",
      "Epoch 440-------------------------------\n",
      "Training loss: 3420.990576553345\n",
      "Test loss: 146798.109375 \n",
      "\n",
      "Epoch 441-------------------------------\n",
      "Training loss: 3630.2234315872192\n",
      "Test loss: 145825.234375 \n",
      "\n",
      "Epoch 442-------------------------------\n",
      "Training loss: 3641.287822341919\n",
      "Test loss: 145359.859375 \n",
      "\n",
      "Epoch 443-------------------------------\n",
      "Training loss: 1404.7599242210388\n",
      "Test loss: 146486.375000 \n",
      "\n",
      "Epoch 444-------------------------------\n",
      "Training loss: 2096.328582572937\n",
      "Test loss: 144965.687500 \n",
      "\n",
      "Epoch 445-------------------------------\n",
      "Training loss: 2387.7678243637083\n",
      "Test loss: 146712.781250 \n",
      "\n",
      "Epoch 446-------------------------------\n",
      "Training loss: 10207.059477615356\n",
      "Test loss: 139507.093750 \n",
      "\n",
      "Epoch 447-------------------------------\n",
      "Training loss: 2489.4374273300173\n",
      "Test loss: 144159.015625 \n",
      "\n",
      "Epoch 448-------------------------------\n",
      "Training loss: 4548.468186378479\n",
      "Test loss: 143628.359375 \n",
      "\n",
      "Epoch 449-------------------------------\n",
      "Training loss: 3646.2802362442017\n",
      "Test loss: 143481.421875 \n",
      "\n",
      "Epoch 450-------------------------------\n",
      "Training loss: 5895.975353240967\n",
      "Test loss: 144483.765625 \n",
      "\n",
      "Epoch 451-------------------------------\n",
      "Training loss: 4810.888259887695\n",
      "Test loss: 144099.453125 \n",
      "\n",
      "Epoch 452-------------------------------\n",
      "Training loss: 1264.2735837936402\n",
      "Test loss: 146925.562500 \n",
      "\n",
      "Epoch 453-------------------------------\n",
      "Training loss: 2848.8659036636354\n",
      "Test loss: 146762.140625 \n",
      "\n",
      "Epoch 454-------------------------------\n",
      "Training loss: 2145.8392827033995\n",
      "Test loss: 139877.734375 \n",
      "\n",
      "Epoch 455-------------------------------\n",
      "Training loss: 6482.484552764892\n",
      "Test loss: 144818.140625 \n",
      "\n",
      "Epoch 456-------------------------------\n",
      "Training loss: 3243.7891302108765\n",
      "Test loss: 145782.828125 \n",
      "\n",
      "Epoch 457-------------------------------\n",
      "Training loss: 1509.5732259750366\n",
      "Test loss: 145745.109375 \n",
      "\n",
      "Epoch 458-------------------------------\n",
      "Training loss: 4252.800016403198\n",
      "Test loss: 145771.343750 \n",
      "\n",
      "Epoch 459-------------------------------\n",
      "Training loss: 2867.812878036499\n",
      "Test loss: 145660.296875 \n",
      "\n",
      "Epoch 460-------------------------------\n",
      "Training loss: 1515.7078680038453\n",
      "Test loss: 147120.609375 \n",
      "\n",
      "Epoch 461-------------------------------\n",
      "Training loss: 1293.5416787147522\n",
      "Test loss: 146224.156250 \n",
      "\n",
      "Epoch 462-------------------------------\n",
      "Training loss: 4855.126759529114\n",
      "Test loss: 144989.234375 \n",
      "\n",
      "Epoch 463-------------------------------\n",
      "Training loss: 1597.0731709480285\n",
      "Test loss: 146109.062500 \n",
      "\n",
      "Epoch 464-------------------------------\n",
      "Training loss: 5179.0907367706295\n",
      "Test loss: 145910.328125 \n",
      "\n",
      "Epoch 465-------------------------------\n",
      "Training loss: 1597.1772012710571\n",
      "Test loss: 146644.375000 \n",
      "\n",
      "Epoch 466-------------------------------\n",
      "Training loss: 6609.447948646545\n",
      "Test loss: 144121.718750 \n",
      "\n",
      "Epoch 467-------------------------------\n",
      "Training loss: 1967.5892811775207\n",
      "Test loss: 145676.671875 \n",
      "\n",
      "Epoch 468-------------------------------\n",
      "Training loss: 1481.092484664917\n",
      "Test loss: 145782.187500 \n",
      "\n",
      "Epoch 469-------------------------------\n",
      "Training loss: 2298.923983860016\n",
      "Test loss: 145311.062500 \n",
      "\n",
      "Epoch 470-------------------------------\n",
      "Training loss: 2763.653537940979\n",
      "Test loss: 144809.171875 \n",
      "\n",
      "Epoch 471-------------------------------\n",
      "Training loss: 4352.8405673980715\n",
      "Test loss: 145838.328125 \n",
      "\n",
      "Epoch 472-------------------------------\n",
      "Training loss: 3080.0015285491945\n",
      "Test loss: 146444.734375 \n",
      "\n",
      "Epoch 473-------------------------------\n",
      "Training loss: 2176.1139059066772\n",
      "Test loss: 146163.968750 \n",
      "\n",
      "Epoch 474-------------------------------\n",
      "Training loss: 2844.4590293884276\n",
      "Test loss: 145258.375000 \n",
      "\n",
      "Epoch 475-------------------------------\n",
      "Training loss: 4753.898631668091\n",
      "Test loss: 142916.796875 \n",
      "\n",
      "Epoch 476-------------------------------\n",
      "Training loss: 2247.4614685058596\n",
      "Test loss: 146218.421875 \n",
      "\n",
      "Epoch 477-------------------------------\n",
      "Training loss: 5491.959491348267\n",
      "Test loss: 143273.437500 \n",
      "\n",
      "Epoch 478-------------------------------\n",
      "Training loss: 2883.9235656738283\n",
      "Test loss: 141911.734375 \n",
      "\n",
      "Epoch 479-------------------------------\n",
      "Training loss: 4400.936513900757\n",
      "Test loss: 145365.781250 \n",
      "\n",
      "Epoch 480-------------------------------\n",
      "Training loss: 1360.8787698745728\n",
      "Test loss: 145793.515625 \n",
      "\n",
      "Epoch 481-------------------------------\n",
      "Training loss: 1817.9261973381042\n",
      "Test loss: 147701.671875 \n",
      "\n",
      "Epoch 482-------------------------------\n",
      "Training loss: 4414.3352475881575\n",
      "Test loss: 146060.796875 \n",
      "\n",
      "Epoch 483-------------------------------\n",
      "Training loss: 3367.737191963196\n",
      "Test loss: 145763.671875 \n",
      "\n",
      "Epoch 484-------------------------------\n",
      "Training loss: 3344.276278305054\n",
      "Test loss: 145759.875000 \n",
      "\n",
      "Epoch 485-------------------------------\n",
      "Training loss: 1651.8613901138306\n",
      "Test loss: 146859.750000 \n",
      "\n",
      "Epoch 486-------------------------------\n",
      "Training loss: 1278.7847246170045\n",
      "Test loss: 146980.859375 \n",
      "\n",
      "Epoch 487-------------------------------\n",
      "Training loss: 3881.2015208244325\n",
      "Test loss: 146213.906250 \n",
      "\n",
      "Epoch 488-------------------------------\n",
      "Training loss: 1651.1325592041017\n",
      "Test loss: 146911.015625 \n",
      "\n",
      "Epoch 489-------------------------------\n",
      "Training loss: 3003.2613628387453\n",
      "Test loss: 146383.562500 \n",
      "\n",
      "Epoch 490-------------------------------\n",
      "Training loss: 2932.9087841033934\n",
      "Test loss: 145875.734375 \n",
      "\n",
      "Epoch 491-------------------------------\n",
      "Training loss: 2247.0941734313965\n",
      "Test loss: 138638.125000 \n",
      "\n",
      "Epoch 492-------------------------------\n",
      "Training loss: 5933.645882225037\n",
      "Test loss: 143420.046875 \n",
      "\n",
      "Epoch 493-------------------------------\n",
      "Training loss: 2803.0236671447756\n",
      "Test loss: 143689.078125 \n",
      "\n",
      "Epoch 494-------------------------------\n",
      "Training loss: 1827.9580806732179\n",
      "Test loss: 145154.250000 \n",
      "\n",
      "Epoch 495-------------------------------\n",
      "Training loss: 2026.2067910194396\n",
      "Test loss: 145868.593750 \n",
      "\n",
      "Epoch 496-------------------------------\n",
      "Training loss: 4384.32130241394\n",
      "Test loss: 145908.703125 \n",
      "\n",
      "Epoch 497-------------------------------\n",
      "Training loss: 2747.0964456558227\n",
      "Test loss: 146544.578125 \n",
      "\n",
      "Epoch 498-------------------------------\n",
      "Training loss: 2709.240573692322\n",
      "Test loss: 144189.843750 \n",
      "\n",
      "Epoch 499-------------------------------\n",
      "Training loss: 3207.730752372742\n",
      "Test loss: 139301.109375 \n",
      "\n",
      "Epoch 500-------------------------------\n",
      "Training loss: 2730.42972946167\n",
      "Test loss: 146807.656250 \n",
      "\n",
      "Epoch 501-------------------------------\n",
      "Training loss: 3236.992005157471\n",
      "Test loss: 146339.968750 \n",
      "\n",
      "Epoch 502-------------------------------\n",
      "Training loss: 2567.4161063194274\n",
      "Test loss: 147068.359375 \n",
      "\n",
      "Epoch 503-------------------------------\n",
      "Training loss: 2032.189945602417\n",
      "Test loss: 146672.593750 \n",
      "\n",
      "Epoch 504-------------------------------\n",
      "Training loss: 3591.9338841438293\n",
      "Test loss: 145646.312500 \n",
      "\n",
      "Epoch 505-------------------------------\n",
      "Training loss: 1418.418331050873\n",
      "Test loss: 142003.718750 \n",
      "\n",
      "Epoch 506-------------------------------\n",
      "Training loss: 3635.229580307007\n",
      "Test loss: 146326.296875 \n",
      "\n",
      "Epoch 507-------------------------------\n",
      "Training loss: 3220.874891281128\n",
      "Test loss: 146074.156250 \n",
      "\n",
      "Epoch 508-------------------------------\n",
      "Training loss: 1542.3030336380004\n",
      "Test loss: 146022.109375 \n",
      "\n",
      "Epoch 509-------------------------------\n",
      "Training loss: 2431.1314701080323\n",
      "Test loss: 146386.062500 \n",
      "\n",
      "Epoch 510-------------------------------\n",
      "Training loss: 4146.145909690857\n",
      "Test loss: 146677.515625 \n",
      "\n",
      "Epoch 511-------------------------------\n",
      "Training loss: 5000.852526664734\n",
      "Test loss: 145612.687500 \n",
      "\n",
      "Epoch 512-------------------------------\n",
      "Training loss: 3139.784334564209\n",
      "Test loss: 145196.281250 \n",
      "\n",
      "Epoch 513-------------------------------\n",
      "Training loss: 1183.8879152297973\n",
      "Test loss: 146909.484375 \n",
      "\n",
      "Epoch 514-------------------------------\n",
      "Training loss: 3677.335629463196\n",
      "Test loss: 137467.640625 \n",
      "\n",
      "Epoch 515-------------------------------\n",
      "Training loss: 3884.1379470825195\n",
      "Test loss: 145466.031250 \n",
      "\n",
      "Epoch 516-------------------------------\n",
      "Training loss: 1870.3114677429198\n",
      "Test loss: 147369.406250 \n",
      "\n",
      "Epoch 517-------------------------------\n",
      "Training loss: 4978.845058727265\n",
      "Test loss: 144979.015625 \n",
      "\n",
      "Epoch 518-------------------------------\n",
      "Training loss: 2319.691186904907\n",
      "Test loss: 146952.875000 \n",
      "\n",
      "Epoch 519-------------------------------\n",
      "Training loss: 1852.1877192497254\n",
      "Test loss: 141536.281250 \n",
      "\n",
      "Epoch 520-------------------------------\n",
      "Training loss: 2622.508835220337\n",
      "Test loss: 146427.390625 \n",
      "\n",
      "Epoch 521-------------------------------\n",
      "Training loss: 2890.6004503250124\n",
      "Test loss: 143589.328125 \n",
      "\n",
      "Epoch 522-------------------------------\n",
      "Training loss: 2959.634781265259\n",
      "Test loss: 145956.984375 \n",
      "\n",
      "Epoch 523-------------------------------\n",
      "Training loss: 2272.409265708923\n",
      "Test loss: 146916.734375 \n",
      "\n",
      "Epoch 524-------------------------------\n",
      "Training loss: 4550.943659210205\n",
      "Test loss: 146175.703125 \n",
      "\n",
      "Epoch 525-------------------------------\n",
      "Training loss: 3333.1453889846803\n",
      "Test loss: 143696.421875 \n",
      "\n",
      "Epoch 526-------------------------------\n",
      "Training loss: 5668.112510299683\n",
      "Test loss: 143466.343750 \n",
      "\n",
      "Epoch 527-------------------------------\n",
      "Training loss: 2425.192915725708\n",
      "Test loss: 145751.718750 \n",
      "\n",
      "Epoch 528-------------------------------\n",
      "Training loss: 2953.720057487488\n",
      "Test loss: 145525.546875 \n",
      "\n",
      "Epoch 529-------------------------------\n",
      "Training loss: 3229.0121788024903\n",
      "Test loss: 146221.609375 \n",
      "\n",
      "Epoch 530-------------------------------\n",
      "Training loss: 2753.371556186676\n",
      "Test loss: 146980.734375 \n",
      "\n",
      "Epoch 531-------------------------------\n",
      "Training loss: 1506.100938796997\n",
      "Test loss: 147050.921875 \n",
      "\n",
      "Epoch 532-------------------------------\n",
      "Training loss: 3741.262495136261\n",
      "Test loss: 146010.031250 \n",
      "\n",
      "Epoch 533-------------------------------\n",
      "Training loss: 1139.5865260124206\n",
      "Test loss: 146381.203125 \n",
      "\n",
      "Epoch 534-------------------------------\n",
      "Training loss: 2280.9709927558897\n",
      "Test loss: 142574.171875 \n",
      "\n",
      "Epoch 535-------------------------------\n",
      "Training loss: 2606.9051626205446\n",
      "Test loss: 147007.234375 \n",
      "\n",
      "Epoch 536-------------------------------\n",
      "Training loss: 3839.512647819519\n",
      "Test loss: 146760.312500 \n",
      "\n",
      "Epoch 537-------------------------------\n",
      "Training loss: 4163.645890331269\n",
      "Test loss: 146107.437500 \n",
      "\n",
      "Epoch 538-------------------------------\n",
      "Training loss: 1821.647544670105\n",
      "Test loss: 146064.890625 \n",
      "\n",
      "Epoch 539-------------------------------\n",
      "Training loss: 1319.29869222641\n",
      "Test loss: 147403.625000 \n",
      "\n",
      "Epoch 540-------------------------------\n",
      "Training loss: 3584.9748889923094\n",
      "Test loss: 144600.343750 \n",
      "\n",
      "Epoch 541-------------------------------\n",
      "Training loss: 4446.015746212006\n",
      "Test loss: 145901.703125 \n",
      "\n",
      "Epoch 542-------------------------------\n",
      "Training loss: 1476.8462348937987\n",
      "Test loss: 143882.671875 \n",
      "\n",
      "Epoch 543-------------------------------\n",
      "Training loss: 2136.4817128658296\n",
      "Test loss: 146898.343750 \n",
      "\n",
      "Epoch 544-------------------------------\n",
      "Training loss: 3210.520472240448\n",
      "Test loss: 145262.890625 \n",
      "\n",
      "Epoch 545-------------------------------\n",
      "Training loss: 1921.9462922096252\n",
      "Test loss: 146840.437500 \n",
      "\n",
      "Epoch 546-------------------------------\n",
      "Training loss: 3166.7363027572633\n",
      "Test loss: 145750.859375 \n",
      "\n",
      "Epoch 547-------------------------------\n",
      "Training loss: 3088.344832801819\n",
      "Test loss: 146390.328125 \n",
      "\n",
      "Epoch 548-------------------------------\n",
      "Training loss: 3697.8612390518188\n",
      "Test loss: 145749.421875 \n",
      "\n",
      "Epoch 549-------------------------------\n",
      "Training loss: 2317.4235681533814\n",
      "Test loss: 146434.140625 \n",
      "\n",
      "Epoch 550-------------------------------\n",
      "Training loss: 3048.6636147499084\n",
      "Test loss: 146566.812500 \n",
      "\n",
      "Epoch 551-------------------------------\n",
      "Training loss: 3388.608517742157\n",
      "Test loss: 146130.812500 \n",
      "\n",
      "Epoch 552-------------------------------\n",
      "Training loss: 2782.62295589447\n",
      "Test loss: 146458.781250 \n",
      "\n",
      "Epoch 553-------------------------------\n",
      "Training loss: 1011.2236788749694\n",
      "Test loss: 146852.968750 \n",
      "\n",
      "Epoch 554-------------------------------\n",
      "Training loss: 3486.294760990143\n",
      "Test loss: 146784.078125 \n",
      "\n",
      "Epoch 555-------------------------------\n",
      "Training loss: 2600.8166958808897\n",
      "Test loss: 146695.250000 \n",
      "\n",
      "Epoch 556-------------------------------\n",
      "Training loss: 2760.611197948456\n",
      "Test loss: 144957.984375 \n",
      "\n",
      "Epoch 557-------------------------------\n",
      "Training loss: 2614.2235918045044\n",
      "Test loss: 146445.000000 \n",
      "\n",
      "Epoch 558-------------------------------\n",
      "Training loss: 2083.237837123871\n",
      "Test loss: 146256.687500 \n",
      "\n",
      "Epoch 559-------------------------------\n",
      "Training loss: 2933.7054273605345\n",
      "Test loss: 143085.000000 \n",
      "\n",
      "Epoch 560-------------------------------\n",
      "Training loss: 5489.124962997436\n",
      "Test loss: 145243.406250 \n",
      "\n",
      "Epoch 561-------------------------------\n",
      "Training loss: 1431.0028797149657\n",
      "Test loss: 146650.359375 \n",
      "\n",
      "Epoch 562-------------------------------\n",
      "Training loss: 2163.6506589889527\n",
      "Test loss: 147452.250000 \n",
      "\n",
      "Epoch 563-------------------------------\n",
      "Training loss: 4115.080463886261\n",
      "Test loss: 146166.656250 \n",
      "\n",
      "Epoch 564-------------------------------\n",
      "Training loss: 1718.914091682434\n",
      "Test loss: 147431.828125 \n",
      "\n",
      "Epoch 565-------------------------------\n",
      "Training loss: 985.1583421230316\n",
      "Test loss: 145081.625000 \n",
      "\n",
      "Epoch 566-------------------------------\n",
      "Training loss: 2943.5525941848755\n",
      "Test loss: 138904.531250 \n",
      "\n",
      "Epoch 567-------------------------------\n",
      "Training loss: 4591.538048934936\n",
      "Test loss: 145339.921875 \n",
      "\n",
      "Epoch 568-------------------------------\n",
      "Training loss: 2235.4327997207643\n",
      "Test loss: 146848.296875 \n",
      "\n",
      "Epoch 569-------------------------------\n",
      "Training loss: 3773.4689076423647\n",
      "Test loss: 146349.281250 \n",
      "\n",
      "Epoch 570-------------------------------\n",
      "Training loss: 1395.532102394104\n",
      "Test loss: 146632.671875 \n",
      "\n",
      "Epoch 571-------------------------------\n",
      "Training loss: 3604.649692821503\n",
      "Test loss: 146575.359375 \n",
      "\n",
      "Epoch 572-------------------------------\n",
      "Training loss: 3897.570874977112\n",
      "Test loss: 146116.968750 \n",
      "\n",
      "Epoch 573-------------------------------\n",
      "Training loss: 6275.539265632629\n",
      "Test loss: 142781.812500 \n",
      "\n",
      "Epoch 574-------------------------------\n",
      "Training loss: 1151.6873094558716\n",
      "Test loss: 143870.531250 \n",
      "\n",
      "Epoch 575-------------------------------\n",
      "Training loss: 1868.5269377708435\n",
      "Test loss: 146318.781250 \n",
      "\n",
      "Epoch 576-------------------------------\n",
      "Training loss: 1970.34144115448\n",
      "Test loss: 146780.765625 \n",
      "\n",
      "Epoch 577-------------------------------\n",
      "Training loss: 4321.0309421539305\n",
      "Test loss: 144485.343750 \n",
      "\n",
      "Epoch 578-------------------------------\n",
      "Training loss: 1415.752742958069\n",
      "Test loss: 146707.093750 \n",
      "\n",
      "Epoch 579-------------------------------\n",
      "Training loss: 5835.047105979919\n",
      "Test loss: 143785.609375 \n",
      "\n",
      "Epoch 580-------------------------------\n",
      "Training loss: 2042.9562120437622\n",
      "Test loss: 146434.000000 \n",
      "\n",
      "Epoch 581-------------------------------\n",
      "Training loss: 1400.9724069595336\n",
      "Test loss: 147237.625000 \n",
      "\n",
      "Epoch 582-------------------------------\n",
      "Training loss: 2220.366730976105\n",
      "Test loss: 147186.015625 \n",
      "\n",
      "Epoch 583-------------------------------\n",
      "Training loss: 2899.0435874938967\n",
      "Test loss: 146761.796875 \n",
      "\n",
      "Epoch 584-------------------------------\n",
      "Training loss: 3191.1356245994566\n",
      "Test loss: 146772.046875 \n",
      "\n",
      "Epoch 585-------------------------------\n",
      "Training loss: 3199.7636076927183\n",
      "Test loss: 140788.625000 \n",
      "\n",
      "Epoch 586-------------------------------\n",
      "Training loss: 2072.2268968582152\n",
      "Test loss: 147371.140625 \n",
      "\n",
      "Epoch 587-------------------------------\n",
      "Training loss: 6802.373128414154\n",
      "Test loss: 143226.281250 \n",
      "\n",
      "Epoch 588-------------------------------\n",
      "Training loss: 2794.5394620895386\n",
      "Test loss: 145691.281250 \n",
      "\n",
      "Epoch 589-------------------------------\n",
      "Training loss: 1577.2475202560424\n",
      "Test loss: 146523.984375 \n",
      "\n",
      "Epoch 590-------------------------------\n",
      "Training loss: 728.6056264400482\n",
      "Test loss: 147894.859375 \n",
      "\n",
      "Epoch 591-------------------------------\n",
      "Training loss: 5460.7470790863035\n",
      "Test loss: 145397.203125 \n",
      "\n",
      "Epoch 592-------------------------------\n",
      "Training loss: 2434.873366737366\n",
      "Test loss: 146167.687500 \n",
      "\n",
      "Epoch 593-------------------------------\n",
      "Training loss: 2743.2203143119814\n",
      "Test loss: 146736.234375 \n",
      "\n",
      "Epoch 594-------------------------------\n",
      "Training loss: 1519.3214790344239\n",
      "Test loss: 146604.328125 \n",
      "\n",
      "Epoch 595-------------------------------\n",
      "Training loss: 2247.0237441062927\n",
      "Test loss: 147624.375000 \n",
      "\n",
      "Epoch 596-------------------------------\n",
      "Training loss: 2402.2134031295777\n",
      "Test loss: 147542.375000 \n",
      "\n",
      "Epoch 597-------------------------------\n",
      "Training loss: 1195.931127166748\n",
      "Test loss: 148002.937500 \n",
      "\n",
      "Epoch 598-------------------------------\n",
      "Training loss: 979.5087232589722\n",
      "Test loss: 146827.265625 \n",
      "\n",
      "Epoch 599-------------------------------\n",
      "Training loss: 3132.7916175842283\n",
      "Test loss: 147367.531250 \n",
      "\n",
      "Epoch 600-------------------------------\n",
      "Training loss: 1520.0551721572876\n",
      "Test loss: 146323.515625 \n",
      "\n",
      "Epoch 601-------------------------------\n",
      "Training loss: 2056.573353290558\n",
      "Test loss: 147039.062500 \n",
      "\n",
      "Epoch 602-------------------------------\n",
      "Training loss: 1839.2079332351684\n",
      "Test loss: 143882.046875 \n",
      "\n",
      "Epoch 603-------------------------------\n",
      "Training loss: 3418.8962226867675\n",
      "Test loss: 145768.515625 \n",
      "\n",
      "Epoch 604-------------------------------\n",
      "Training loss: 5492.386626243591\n",
      "Test loss: 146607.250000 \n",
      "\n",
      "Epoch 605-------------------------------\n",
      "Training loss: 2441.2912126541137\n",
      "Test loss: 145920.281250 \n",
      "\n",
      "Epoch 606-------------------------------\n",
      "Training loss: 1579.0618028640747\n",
      "Test loss: 146634.843750 \n",
      "\n",
      "Epoch 607-------------------------------\n",
      "Training loss: 1755.45218334198\n",
      "Test loss: 144108.125000 \n",
      "\n",
      "Epoch 608-------------------------------\n",
      "Training loss: 4515.04233417511\n",
      "Test loss: 146173.656250 \n",
      "\n",
      "Epoch 609-------------------------------\n",
      "Training loss: 1666.572421169281\n",
      "Test loss: 146388.843750 \n",
      "\n",
      "Epoch 610-------------------------------\n",
      "Training loss: 1287.9803284645081\n",
      "Test loss: 148082.921875 \n",
      "\n",
      "Epoch 611-------------------------------\n",
      "Training loss: 1452.9194918632506\n",
      "Test loss: 147254.812500 \n",
      "\n",
      "Epoch 612-------------------------------\n",
      "Training loss: 1991.0424437522888\n",
      "Test loss: 147550.453125 \n",
      "\n",
      "Epoch 613-------------------------------\n",
      "Training loss: 2283.687031841278\n",
      "Test loss: 139139.015625 \n",
      "\n",
      "Epoch 614-------------------------------\n",
      "Training loss: 3255.940189743042\n",
      "Test loss: 145595.984375 \n",
      "\n",
      "Epoch 615-------------------------------\n",
      "Training loss: 2446.838315010071\n",
      "Test loss: 144210.218750 \n",
      "\n",
      "Epoch 616-------------------------------\n",
      "Training loss: 2170.6779144763946\n",
      "Test loss: 145232.000000 \n",
      "\n",
      "Epoch 617-------------------------------\n",
      "Training loss: 3559.955850315094\n",
      "Test loss: 146399.218750 \n",
      "\n",
      "Epoch 618-------------------------------\n",
      "Training loss: 3935.573729991913\n",
      "Test loss: 146275.296875 \n",
      "\n",
      "Epoch 619-------------------------------\n",
      "Training loss: 1090.1830954551697\n",
      "Test loss: 147480.515625 \n",
      "\n",
      "Epoch 620-------------------------------\n",
      "Training loss: 2135.601905632019\n",
      "Test loss: 147452.796875 \n",
      "\n",
      "Epoch 621-------------------------------\n",
      "Training loss: 1286.0884700775146\n",
      "Test loss: 147590.078125 \n",
      "\n",
      "Epoch 622-------------------------------\n",
      "Training loss: 6167.411170959473\n",
      "Test loss: 145072.937500 \n",
      "\n",
      "Epoch 623-------------------------------\n",
      "Training loss: 2765.949349594116\n",
      "Test loss: 145494.218750 \n",
      "\n",
      "Epoch 624-------------------------------\n",
      "Training loss: 1903.1640480041503\n",
      "Test loss: 146718.390625 \n",
      "\n",
      "Epoch 625-------------------------------\n",
      "Training loss: 2640.8060936927795\n",
      "Test loss: 146466.171875 \n",
      "\n",
      "Epoch 626-------------------------------\n",
      "Training loss: 1198.048722743988\n",
      "Test loss: 147091.796875 \n",
      "\n",
      "Epoch 627-------------------------------\n",
      "Training loss: 4400.291660118103\n",
      "Test loss: 145580.953125 \n",
      "\n",
      "Epoch 628-------------------------------\n",
      "Training loss: 2677.3795996665954\n",
      "Test loss: 146921.234375 \n",
      "\n",
      "Epoch 629-------------------------------\n",
      "Training loss: 1490.8397263526917\n",
      "Test loss: 147074.687500 \n",
      "\n",
      "Epoch 630-------------------------------\n",
      "Training loss: 745.5109666824341\n",
      "Test loss: 147773.578125 \n",
      "\n",
      "Epoch 631-------------------------------\n",
      "Training loss: 3808.737697315216\n",
      "Test loss: 146866.640625 \n",
      "\n",
      "Epoch 632-------------------------------\n",
      "Training loss: 1277.1932284355164\n",
      "Test loss: 147346.828125 \n",
      "\n",
      "Epoch 633-------------------------------\n",
      "Training loss: 1687.638777089119\n",
      "Test loss: 147374.156250 \n",
      "\n",
      "Epoch 634-------------------------------\n",
      "Training loss: 10628.618289852142\n",
      "Test loss: 139456.093750 \n",
      "\n",
      "Epoch 635-------------------------------\n",
      "Training loss: 1217.3556838989257\n",
      "Test loss: 144892.625000 \n",
      "\n",
      "Epoch 636-------------------------------\n",
      "Training loss: 1199.784225845337\n",
      "Test loss: 147854.140625 \n",
      "\n",
      "Epoch 637-------------------------------\n",
      "Training loss: 2111.5090022087097\n",
      "Test loss: 139995.890625 \n",
      "\n",
      "Epoch 638-------------------------------\n",
      "Training loss: 3374.8714530944826\n",
      "Test loss: 146741.453125 \n",
      "\n",
      "Epoch 639-------------------------------\n",
      "Training loss: 2266.2368604660032\n",
      "Test loss: 147868.203125 \n",
      "\n",
      "Epoch 640-------------------------------\n",
      "Training loss: 702.533281993866\n",
      "Test loss: 147661.843750 \n",
      "\n",
      "Epoch 641-------------------------------\n",
      "Training loss: 1293.1704896450042\n",
      "Test loss: 145068.687500 \n",
      "\n",
      "Epoch 642-------------------------------\n",
      "Training loss: 2104.7426495552063\n",
      "Test loss: 146684.265625 \n",
      "\n",
      "Epoch 643-------------------------------\n",
      "Training loss: 1321.7769866943358\n",
      "Test loss: 148042.187500 \n",
      "\n",
      "Epoch 644-------------------------------\n",
      "Training loss: 1340.877337694168\n",
      "Test loss: 146959.046875 \n",
      "\n",
      "Epoch 645-------------------------------\n",
      "Training loss: 2526.2857712745667\n",
      "Test loss: 146501.937500 \n",
      "\n",
      "Epoch 646-------------------------------\n",
      "Training loss: 1535.033921146393\n",
      "Test loss: 147765.687500 \n",
      "\n",
      "Epoch 647-------------------------------\n",
      "Training loss: 6033.868702411652\n",
      "Test loss: 146025.843750 \n",
      "\n",
      "Epoch 648-------------------------------\n",
      "Training loss: 2561.374306678772\n",
      "Test loss: 146480.078125 \n",
      "\n",
      "Epoch 649-------------------------------\n",
      "Training loss: 1431.0240832328795\n",
      "Test loss: 146726.031250 \n",
      "\n",
      "Epoch 650-------------------------------\n",
      "Training loss: 3655.3247443199157\n",
      "Test loss: 139872.390625 \n",
      "\n",
      "Epoch 651-------------------------------\n",
      "Training loss: 1909.7599493026732\n",
      "Test loss: 147659.609375 \n",
      "\n",
      "Epoch 652-------------------------------\n",
      "Training loss: 2722.9029536724092\n",
      "Test loss: 146580.250000 \n",
      "\n",
      "Epoch 653-------------------------------\n",
      "Training loss: 1329.030090713501\n",
      "Test loss: 147601.000000 \n",
      "\n",
      "Epoch 654-------------------------------\n",
      "Training loss: 2098.0045294761658\n",
      "Test loss: 147104.796875 \n",
      "\n",
      "Epoch 655-------------------------------\n",
      "Training loss: 2187.978083229065\n",
      "Test loss: 145792.578125 \n",
      "\n",
      "Epoch 656-------------------------------\n",
      "Training loss: 2944.89937210083\n",
      "Test loss: 147477.671875 \n",
      "\n",
      "Epoch 657-------------------------------\n",
      "Training loss: 1296.950524520874\n",
      "Test loss: 147656.265625 \n",
      "\n",
      "Epoch 658-------------------------------\n",
      "Training loss: 1505.9488228797914\n",
      "Test loss: 143341.046875 \n",
      "\n",
      "Epoch 659-------------------------------\n",
      "Training loss: 1697.5139770507812\n",
      "Test loss: 146536.703125 \n",
      "\n",
      "Epoch 660-------------------------------\n",
      "Training loss: 2840.7997183322905\n",
      "Test loss: 147585.531250 \n",
      "\n",
      "Epoch 661-------------------------------\n",
      "Training loss: 1246.3300368547439\n",
      "Test loss: 148177.890625 \n",
      "\n",
      "Epoch 662-------------------------------\n",
      "Training loss: 729.7106328487396\n",
      "Test loss: 147902.078125 \n",
      "\n",
      "Epoch 663-------------------------------\n",
      "Training loss: 2889.8007872581484\n",
      "Test loss: 144280.312500 \n",
      "\n",
      "Epoch 664-------------------------------\n",
      "Training loss: 1618.822672176361\n",
      "Test loss: 146185.453125 \n",
      "\n",
      "Epoch 665-------------------------------\n",
      "Training loss: 1852.2317373275757\n",
      "Test loss: 148006.656250 \n",
      "\n",
      "Epoch 666-------------------------------\n",
      "Training loss: 1827.4963118553162\n",
      "Test loss: 147621.765625 \n",
      "\n",
      "Epoch 667-------------------------------\n",
      "Training loss: 1789.1758819580077\n",
      "Test loss: 146748.046875 \n",
      "\n",
      "Epoch 668-------------------------------\n",
      "Training loss: 5484.051645565033\n",
      "Test loss: 140135.812500 \n",
      "\n",
      "Epoch 669-------------------------------\n",
      "Training loss: 2105.187926006317\n",
      "Test loss: 146301.468750 \n",
      "\n",
      "Epoch 670-------------------------------\n",
      "Training loss: 2417.7721424102783\n",
      "Test loss: 147280.734375 \n",
      "\n",
      "Epoch 671-------------------------------\n",
      "Training loss: 1477.6196677207947\n",
      "Test loss: 146958.015625 \n",
      "\n",
      "Epoch 672-------------------------------\n",
      "Training loss: 1223.347758960724\n",
      "Test loss: 147681.359375 \n",
      "\n",
      "Epoch 673-------------------------------\n",
      "Training loss: 2128.1057938098907\n",
      "Test loss: 148033.718750 \n",
      "\n",
      "Epoch 674-------------------------------\n",
      "Training loss: 1020.5920075416565\n",
      "Test loss: 148424.859375 \n",
      "\n",
      "Epoch 675-------------------------------\n",
      "Training loss: 834.5849782466888\n",
      "Test loss: 147732.906250 \n",
      "\n",
      "Epoch 676-------------------------------\n",
      "Training loss: 729.0760686874389\n",
      "Test loss: 148341.921875 \n",
      "\n",
      "Epoch 677-------------------------------\n",
      "Training loss: 2094.903474855423\n",
      "Test loss: 147348.984375 \n",
      "\n",
      "Epoch 678-------------------------------\n",
      "Training loss: 3724.6318544864653\n",
      "Test loss: 147230.156250 \n",
      "\n",
      "Epoch 679-------------------------------\n",
      "Training loss: 1322.871335887909\n",
      "Test loss: 146896.859375 \n",
      "\n",
      "Epoch 680-------------------------------\n",
      "Training loss: 2349.319345855713\n",
      "Test loss: 146282.906250 \n",
      "\n",
      "Epoch 681-------------------------------\n",
      "Training loss: 1653.8183589935302\n",
      "Test loss: 147637.359375 \n",
      "\n",
      "Epoch 682-------------------------------\n",
      "Training loss: 2823.3261788368227\n",
      "Test loss: 147411.406250 \n",
      "\n",
      "Epoch 683-------------------------------\n",
      "Training loss: 2542.116200733185\n",
      "Test loss: 147034.093750 \n",
      "\n",
      "Epoch 684-------------------------------\n",
      "Training loss: 2020.7065494537353\n",
      "Test loss: 146339.578125 \n",
      "\n",
      "Epoch 685-------------------------------\n",
      "Training loss: 1688.768184518814\n",
      "Test loss: 146798.968750 \n",
      "\n",
      "Epoch 686-------------------------------\n",
      "Training loss: 1886.3158334732057\n",
      "Test loss: 147318.531250 \n",
      "\n",
      "Epoch 687-------------------------------\n",
      "Training loss: 1879.9429850578308\n",
      "Test loss: 147345.359375 \n",
      "\n",
      "Epoch 688-------------------------------\n",
      "Training loss: 1111.148355960846\n",
      "Test loss: 147447.093750 \n",
      "\n",
      "Epoch 689-------------------------------\n",
      "Training loss: 3784.100532722473\n",
      "Test loss: 147231.359375 \n",
      "\n",
      "Epoch 690-------------------------------\n",
      "Training loss: 1360.8226619243621\n",
      "Test loss: 147413.812500 \n",
      "\n",
      "Epoch 691-------------------------------\n",
      "Training loss: 893.8736999034882\n",
      "Test loss: 147996.125000 \n",
      "\n",
      "Epoch 692-------------------------------\n",
      "Training loss: 2815.0604964733125\n",
      "Test loss: 147188.296875 \n",
      "\n",
      "Epoch 693-------------------------------\n",
      "Training loss: 4289.3162371635435\n",
      "Test loss: 146982.812500 \n",
      "\n",
      "Epoch 694-------------------------------\n",
      "Training loss: 2085.171211338043\n",
      "Test loss: 147304.375000 \n",
      "\n",
      "Epoch 695-------------------------------\n",
      "Training loss: 2800.284194278717\n",
      "Test loss: 147067.265625 \n",
      "\n",
      "Epoch 696-------------------------------\n",
      "Training loss: 5350.593743038177\n",
      "Test loss: 138508.046875 \n",
      "\n",
      "Epoch 697-------------------------------\n",
      "Training loss: 5161.385923576355\n",
      "Test loss: 144636.437500 \n",
      "\n",
      "Epoch 698-------------------------------\n",
      "Training loss: 1316.504005241394\n",
      "Test loss: 146117.515625 \n",
      "\n",
      "Epoch 699-------------------------------\n",
      "Training loss: 2820.449334907532\n",
      "Test loss: 146788.093750 \n",
      "\n",
      "Epoch 700-------------------------------\n",
      "Training loss: 2331.993152809143\n",
      "Test loss: 146988.187500 \n",
      "\n",
      "Epoch 701-------------------------------\n",
      "Training loss: 1305.7698095321655\n",
      "Test loss: 148213.671875 \n",
      "\n",
      "Epoch 702-------------------------------\n",
      "Training loss: 2629.383050775528\n",
      "Test loss: 147228.156250 \n",
      "\n",
      "Epoch 703-------------------------------\n",
      "Training loss: 1082.2381012439728\n",
      "Test loss: 148410.734375 \n",
      "\n",
      "Epoch 704-------------------------------\n",
      "Training loss: 2658.62063164711\n",
      "Test loss: 147246.218750 \n",
      "\n",
      "Epoch 705-------------------------------\n",
      "Training loss: 3410.288787126541\n",
      "Test loss: 146442.187500 \n",
      "\n",
      "Epoch 706-------------------------------\n",
      "Training loss: 1360.304632472992\n",
      "Test loss: 146114.062500 \n",
      "\n",
      "Epoch 707-------------------------------\n",
      "Training loss: 1536.0615995407104\n",
      "Test loss: 147277.343750 \n",
      "\n",
      "Epoch 708-------------------------------\n",
      "Training loss: 2006.8411794662475\n",
      "Test loss: 147633.250000 \n",
      "\n",
      "Epoch 709-------------------------------\n",
      "Training loss: 1075.243944311142\n",
      "Test loss: 147743.406250 \n",
      "\n",
      "Epoch 710-------------------------------\n",
      "Training loss: 4342.386764717102\n",
      "Test loss: 145485.156250 \n",
      "\n",
      "Epoch 711-------------------------------\n",
      "Training loss: 1955.3198287963867\n",
      "Test loss: 147323.765625 \n",
      "\n",
      "Epoch 712-------------------------------\n",
      "Training loss: 1813.7766070842742\n",
      "Test loss: 147850.625000 \n",
      "\n",
      "Epoch 713-------------------------------\n",
      "Training loss: 1955.821701192856\n",
      "Test loss: 146775.343750 \n",
      "\n",
      "Epoch 714-------------------------------\n",
      "Training loss: 2298.512551212311\n",
      "Test loss: 143932.312500 \n",
      "\n",
      "Epoch 715-------------------------------\n",
      "Training loss: 4242.117800331116\n",
      "Test loss: 146327.375000 \n",
      "\n",
      "Epoch 716-------------------------------\n",
      "Training loss: 767.9684587478638\n",
      "Test loss: 146822.328125 \n",
      "\n",
      "Epoch 717-------------------------------\n",
      "Training loss: 1817.6793920993805\n",
      "Test loss: 144443.656250 \n",
      "\n",
      "Epoch 718-------------------------------\n",
      "Training loss: 1483.1663365364075\n",
      "Test loss: 143820.796875 \n",
      "\n",
      "Epoch 719-------------------------------\n",
      "Training loss: 3218.4877888679503\n",
      "Test loss: 146349.109375 \n",
      "\n",
      "Epoch 720-------------------------------\n",
      "Training loss: 853.6950646400452\n",
      "Test loss: 148515.859375 \n",
      "\n",
      "Epoch 721-------------------------------\n",
      "Training loss: 1188.8987161159516\n",
      "Test loss: 147867.984375 \n",
      "\n",
      "Epoch 722-------------------------------\n",
      "Training loss: 2002.310719203949\n",
      "Test loss: 146710.718750 \n",
      "\n",
      "Epoch 723-------------------------------\n",
      "Training loss: 1740.0858166217804\n",
      "Test loss: 146166.250000 \n",
      "\n",
      "Epoch 724-------------------------------\n",
      "Training loss: 4194.860585594177\n",
      "Test loss: 146871.421875 \n",
      "\n",
      "Epoch 725-------------------------------\n",
      "Training loss: 5106.505234718323\n",
      "Test loss: 145366.140625 \n",
      "\n",
      "Epoch 726-------------------------------\n",
      "Training loss: 1424.847845363617\n",
      "Test loss: 145576.437500 \n",
      "\n",
      "Epoch 727-------------------------------\n",
      "Training loss: 1240.2304186820984\n",
      "Test loss: 147393.515625 \n",
      "\n",
      "Epoch 728-------------------------------\n",
      "Training loss: 5703.767528104782\n",
      "Test loss: 143534.250000 \n",
      "\n",
      "Epoch 729-------------------------------\n",
      "Training loss: 1778.0053069114686\n",
      "Test loss: 147639.078125 \n",
      "\n",
      "Epoch 730-------------------------------\n",
      "Training loss: 4213.634357738495\n",
      "Test loss: 144585.140625 \n",
      "\n",
      "Epoch 731-------------------------------\n",
      "Training loss: 2652.1047666549684\n",
      "Test loss: 146240.718750 \n",
      "\n",
      "Epoch 732-------------------------------\n",
      "Training loss: 3231.5534192085265\n",
      "Test loss: 141887.593750 \n",
      "\n",
      "Epoch 733-------------------------------\n",
      "Training loss: 3384.9563224315643\n",
      "Test loss: 146775.500000 \n",
      "\n",
      "Epoch 734-------------------------------\n",
      "Training loss: 814.8827967643738\n",
      "Test loss: 147506.812500 \n",
      "\n",
      "Epoch 735-------------------------------\n",
      "Training loss: 2251.893756008148\n",
      "Test loss: 147547.765625 \n",
      "\n",
      "Epoch 736-------------------------------\n",
      "Training loss: 1469.2993526935577\n",
      "Test loss: 147211.000000 \n",
      "\n",
      "Epoch 737-------------------------------\n",
      "Training loss: 1740.0505626678466\n",
      "Test loss: 145975.421875 \n",
      "\n",
      "Epoch 738-------------------------------\n",
      "Training loss: 1575.2539550304414\n",
      "Test loss: 148267.468750 \n",
      "\n",
      "Epoch 739-------------------------------\n",
      "Training loss: 1425.2630152225495\n",
      "Test loss: 146409.343750 \n",
      "\n",
      "Epoch 740-------------------------------\n",
      "Training loss: 3122.206724500656\n",
      "Test loss: 147093.296875 \n",
      "\n",
      "Epoch 741-------------------------------\n",
      "Training loss: 2519.051381969452\n",
      "Test loss: 145424.562500 \n",
      "\n",
      "Epoch 742-------------------------------\n",
      "Training loss: 1530.3874334335328\n",
      "Test loss: 146957.031250 \n",
      "\n",
      "Epoch 743-------------------------------\n",
      "Training loss: 1262.260662317276\n",
      "Test loss: 148056.265625 \n",
      "\n",
      "Epoch 744-------------------------------\n",
      "Training loss: 2704.8416711330415\n",
      "Test loss: 147816.000000 \n",
      "\n",
      "Epoch 745-------------------------------\n",
      "Training loss: 1087.9760846138001\n",
      "Test loss: 147861.171875 \n",
      "\n",
      "Epoch 746-------------------------------\n",
      "Training loss: 1454.9250495910644\n",
      "Test loss: 148129.937500 \n",
      "\n",
      "Epoch 747-------------------------------\n",
      "Training loss: 1035.63263630867\n",
      "Test loss: 148596.609375 \n",
      "\n",
      "Epoch 748-------------------------------\n",
      "Training loss: 4311.997201490402\n",
      "Test loss: 144808.500000 \n",
      "\n",
      "Epoch 749-------------------------------\n",
      "Training loss: 2205.0606033325193\n",
      "Test loss: 147563.406250 \n",
      "\n",
      "Epoch 750-------------------------------\n",
      "Training loss: 2223.587843608856\n",
      "Test loss: 146188.375000 \n",
      "\n",
      "Epoch 751-------------------------------\n",
      "Training loss: 2316.989694595337\n",
      "Test loss: 146842.718750 \n",
      "\n",
      "Epoch 752-------------------------------\n",
      "Training loss: 663.1132768630981\n",
      "Test loss: 147833.921875 \n",
      "\n",
      "Epoch 753-------------------------------\n",
      "Training loss: 1199.486127281189\n",
      "Test loss: 147756.468750 \n",
      "\n",
      "Epoch 754-------------------------------\n",
      "Training loss: 2234.5752235889436\n",
      "Test loss: 148059.109375 \n",
      "\n",
      "Epoch 755-------------------------------\n",
      "Training loss: 4909.3415343284605\n",
      "Test loss: 146182.593750 \n",
      "\n",
      "Epoch 756-------------------------------\n",
      "Training loss: 2080.3804735183717\n",
      "Test loss: 145523.375000 \n",
      "\n",
      "Epoch 757-------------------------------\n",
      "Training loss: 1652.6100966453553\n",
      "Test loss: 146212.625000 \n",
      "\n",
      "Epoch 758-------------------------------\n",
      "Training loss: 3463.0226748466494\n",
      "Test loss: 147448.187500 \n",
      "\n",
      "Epoch 759-------------------------------\n",
      "Training loss: 788.6707231521607\n",
      "Test loss: 148189.328125 \n",
      "\n",
      "Epoch 760-------------------------------\n",
      "Training loss: 2780.1305899143217\n",
      "Test loss: 147514.468750 \n",
      "\n",
      "Epoch 761-------------------------------\n",
      "Training loss: 1409.7167465686798\n",
      "Test loss: 147232.968750 \n",
      "\n",
      "Epoch 762-------------------------------\n",
      "Training loss: 5261.134674835205\n",
      "Test loss: 148465.218750 \n",
      "\n",
      "Epoch 763-------------------------------\n",
      "Training loss: 2182.987652492523\n",
      "Test loss: 146459.718750 \n",
      "\n",
      "Epoch 764-------------------------------\n",
      "Training loss: 3943.8029165267944\n",
      "Test loss: 146698.843750 \n",
      "\n",
      "Epoch 765-------------------------------\n",
      "Training loss: 444.07830266952516\n",
      "Test loss: 147056.296875 \n",
      "\n",
      "Epoch 766-------------------------------\n",
      "Training loss: 2045.9579871177673\n",
      "Test loss: 146393.796875 \n",
      "\n",
      "Epoch 767-------------------------------\n",
      "Training loss: 1742.7837785720826\n",
      "Test loss: 148116.968750 \n",
      "\n",
      "Epoch 768-------------------------------\n",
      "Training loss: 1286.2006671905517\n",
      "Test loss: 147929.703125 \n",
      "\n",
      "Epoch 769-------------------------------\n",
      "Training loss: 5205.733213043213\n",
      "Test loss: 146619.984375 \n",
      "\n",
      "Epoch 770-------------------------------\n",
      "Training loss: 1539.383963251114\n",
      "Test loss: 146175.484375 \n",
      "\n",
      "Epoch 771-------------------------------\n",
      "Training loss: 1239.3151647090913\n",
      "Test loss: 145099.125000 \n",
      "\n",
      "Epoch 772-------------------------------\n",
      "Training loss: 2623.5202116966248\n",
      "Test loss: 145443.375000 \n",
      "\n",
      "Epoch 773-------------------------------\n",
      "Training loss: 1714.0827818870544\n",
      "Test loss: 146573.640625 \n",
      "\n",
      "Epoch 774-------------------------------\n",
      "Training loss: 2943.0254053115846\n",
      "Test loss: 146056.546875 \n",
      "\n",
      "Epoch 775-------------------------------\n",
      "Training loss: 1159.4643318653107\n",
      "Test loss: 147837.750000 \n",
      "\n",
      "Epoch 776-------------------------------\n",
      "Training loss: 921.524307012558\n",
      "Test loss: 147972.062500 \n",
      "\n",
      "Epoch 777-------------------------------\n",
      "Training loss: 1267.9851340293885\n",
      "Test loss: 139280.093750 \n",
      "\n",
      "Epoch 778-------------------------------\n",
      "Training loss: 1893.8626030445098\n",
      "Test loss: 147812.328125 \n",
      "\n",
      "Epoch 779-------------------------------\n",
      "Training loss: 3177.7502113819123\n",
      "Test loss: 147627.968750 \n",
      "\n",
      "Epoch 780-------------------------------\n",
      "Training loss: 1834.2381009101869\n",
      "Test loss: 145292.046875 \n",
      "\n",
      "Epoch 781-------------------------------\n",
      "Training loss: 2333.149280166626\n",
      "Test loss: 146726.312500 \n",
      "\n",
      "Epoch 782-------------------------------\n",
      "Training loss: 572.5915078163147\n",
      "Test loss: 148024.578125 \n",
      "\n",
      "Epoch 783-------------------------------\n",
      "Training loss: 2357.081443309784\n",
      "Test loss: 146933.593750 \n",
      "\n",
      "Epoch 784-------------------------------\n",
      "Training loss: 2296.2779671669005\n",
      "Test loss: 146930.906250 \n",
      "\n",
      "Epoch 785-------------------------------\n",
      "Training loss: 3203.2484698295593\n",
      "Test loss: 147095.171875 \n",
      "\n",
      "Epoch 786-------------------------------\n",
      "Training loss: 2406.121245765686\n",
      "Test loss: 146423.562500 \n",
      "\n",
      "Epoch 787-------------------------------\n",
      "Training loss: 4461.700091552734\n",
      "Test loss: 144847.593750 \n",
      "\n",
      "Epoch 788-------------------------------\n",
      "Training loss: 2512.513843536377\n",
      "Test loss: 147478.640625 \n",
      "\n",
      "Epoch 789-------------------------------\n",
      "Training loss: 1876.3693692207337\n",
      "Test loss: 144839.828125 \n",
      "\n",
      "Epoch 790-------------------------------\n",
      "Training loss: 2995.7062236785887\n",
      "Test loss: 142813.859375 \n",
      "\n",
      "Epoch 791-------------------------------\n",
      "Training loss: 1922.8048877716064\n",
      "Test loss: 147553.125000 \n",
      "\n",
      "Epoch 792-------------------------------\n",
      "Training loss: 821.7652370929718\n",
      "Test loss: 146570.703125 \n",
      "\n",
      "Epoch 793-------------------------------\n",
      "Training loss: 3844.7887263298035\n",
      "Test loss: 143975.234375 \n",
      "\n",
      "Epoch 794-------------------------------\n",
      "Training loss: 2966.518182182312\n",
      "Test loss: 145788.765625 \n",
      "\n",
      "Epoch 795-------------------------------\n",
      "Training loss: 1812.9685012817383\n",
      "Test loss: 145567.875000 \n",
      "\n",
      "Epoch 796-------------------------------\n",
      "Training loss: 2574.2077114105223\n",
      "Test loss: 144125.671875 \n",
      "\n",
      "Epoch 797-------------------------------\n",
      "Training loss: 1289.4898688316346\n",
      "Test loss: 147138.937500 \n",
      "\n",
      "Epoch 798-------------------------------\n",
      "Training loss: 1808.4521382808684\n",
      "Test loss: 148381.046875 \n",
      "\n",
      "Epoch 799-------------------------------\n",
      "Training loss: 1761.5473855495452\n",
      "Test loss: 147993.328125 \n",
      "\n",
      "Epoch 800-------------------------------\n",
      "Training loss: 2054.2404156684875\n",
      "Test loss: 147526.937500 \n",
      "\n",
      "Epoch 801-------------------------------\n",
      "Training loss: 1488.761395549774\n",
      "Test loss: 146863.953125 \n",
      "\n",
      "Epoch 802-------------------------------\n",
      "Training loss: 1674.5216275215148\n",
      "Test loss: 147937.937500 \n",
      "\n",
      "Epoch 803-------------------------------\n",
      "Training loss: 3230.616437101364\n",
      "Test loss: 139333.812500 \n",
      "\n",
      "Epoch 804-------------------------------\n",
      "Training loss: 4036.816637611389\n",
      "Test loss: 146344.078125 \n",
      "\n",
      "Epoch 805-------------------------------\n",
      "Training loss: 1808.3449392318726\n",
      "Test loss: 146539.406250 \n",
      "\n",
      "Epoch 806-------------------------------\n",
      "Training loss: 1862.9656414985657\n",
      "Test loss: 146963.062500 \n",
      "\n",
      "Epoch 807-------------------------------\n",
      "Training loss: 1208.7102236747742\n",
      "Test loss: 147873.281250 \n",
      "\n",
      "Epoch 808-------------------------------\n",
      "Training loss: 1775.5215025901794\n",
      "Test loss: 146885.562500 \n",
      "\n",
      "Epoch 809-------------------------------\n",
      "Training loss: 1949.040562772751\n",
      "Test loss: 147627.937500 \n",
      "\n",
      "Epoch 810-------------------------------\n",
      "Training loss: 763.8309546947479\n",
      "Test loss: 148108.421875 \n",
      "\n",
      "Epoch 811-------------------------------\n",
      "Training loss: 1069.062036037445\n",
      "Test loss: 145679.421875 \n",
      "\n",
      "Epoch 812-------------------------------\n",
      "Training loss: 1600.0645952701568\n",
      "Test loss: 146982.343750 \n",
      "\n",
      "Epoch 813-------------------------------\n",
      "Training loss: 949.7137570381165\n",
      "Test loss: 146584.093750 \n",
      "\n",
      "Epoch 814-------------------------------\n",
      "Training loss: 1813.8475903749465\n",
      "Test loss: 147154.562500 \n",
      "\n",
      "Epoch 815-------------------------------\n",
      "Training loss: 3161.7180329799653\n",
      "Test loss: 144285.437500 \n",
      "\n",
      "Epoch 816-------------------------------\n",
      "Training loss: 6801.658552551269\n",
      "Test loss: 143255.578125 \n",
      "\n",
      "Epoch 817-------------------------------\n",
      "Training loss: 2689.712948989868\n",
      "Test loss: 145141.968750 \n",
      "\n",
      "Epoch 818-------------------------------\n",
      "Training loss: 2320.561340522766\n",
      "Test loss: 144457.781250 \n",
      "\n",
      "Epoch 819-------------------------------\n",
      "Training loss: 2657.235370826721\n",
      "Test loss: 146927.968750 \n",
      "\n",
      "Epoch 820-------------------------------\n",
      "Training loss: 3722.5599294662475\n",
      "Test loss: 146763.484375 \n",
      "\n",
      "Epoch 821-------------------------------\n",
      "Training loss: 1562.4479092597962\n",
      "Test loss: 147092.281250 \n",
      "\n",
      "Epoch 822-------------------------------\n",
      "Training loss: 1002.1400959968566\n",
      "Test loss: 145188.406250 \n",
      "\n",
      "Epoch 823-------------------------------\n",
      "Training loss: 4138.961485862732\n",
      "Test loss: 146982.671875 \n",
      "\n",
      "Epoch 824-------------------------------\n",
      "Training loss: 1385.3126570224763\n",
      "Test loss: 147473.296875 \n",
      "\n",
      "Epoch 825-------------------------------\n",
      "Training loss: 1555.6655512809753\n",
      "Test loss: 148052.781250 \n",
      "\n",
      "Epoch 826-------------------------------\n",
      "Training loss: 544.4225828170777\n",
      "Test loss: 148133.171875 \n",
      "\n",
      "Epoch 827-------------------------------\n",
      "Training loss: 1080.7140779733659\n",
      "Test loss: 147750.671875 \n",
      "\n",
      "Epoch 828-------------------------------\n",
      "Training loss: 1091.9077260255813\n",
      "Test loss: 148362.296875 \n",
      "\n",
      "Epoch 829-------------------------------\n",
      "Training loss: 1553.073554635048\n",
      "Test loss: 147268.562500 \n",
      "\n",
      "Epoch 830-------------------------------\n",
      "Training loss: 1006.9579725265503\n",
      "Test loss: 148280.343750 \n",
      "\n",
      "Epoch 831-------------------------------\n",
      "Training loss: 820.3226071834564\n",
      "Test loss: 147900.953125 \n",
      "\n",
      "Epoch 832-------------------------------\n",
      "Training loss: 2435.1777112960817\n",
      "Test loss: 141066.218750 \n",
      "\n",
      "Epoch 833-------------------------------\n",
      "Training loss: 1193.6835299491881\n",
      "Test loss: 147892.843750 \n",
      "\n",
      "Epoch 834-------------------------------\n",
      "Training loss: 1077.6161351680755\n",
      "Test loss: 144208.640625 \n",
      "\n",
      "Epoch 835-------------------------------\n",
      "Training loss: 2650.9112705230714\n",
      "Test loss: 141770.875000 \n",
      "\n",
      "Epoch 836-------------------------------\n",
      "Training loss: 1980.0369193553925\n",
      "Test loss: 142574.906250 \n",
      "\n",
      "Epoch 837-------------------------------\n",
      "Training loss: 885.581963968277\n",
      "Test loss: 148391.468750 \n",
      "\n",
      "Epoch 838-------------------------------\n",
      "Training loss: 2008.2129923582077\n",
      "Test loss: 148450.859375 \n",
      "\n",
      "Epoch 839-------------------------------\n",
      "Training loss: 1986.341917181015\n",
      "Test loss: 148041.140625 \n",
      "\n",
      "Epoch 840-------------------------------\n",
      "Training loss: 1436.5877846240996\n",
      "Test loss: 148211.375000 \n",
      "\n",
      "Epoch 841-------------------------------\n",
      "Training loss: 3039.391774511337\n",
      "Test loss: 141612.406250 \n",
      "\n",
      "Epoch 842-------------------------------\n",
      "Training loss: 2568.105054950714\n",
      "Test loss: 146176.968750 \n",
      "\n",
      "Epoch 843-------------------------------\n",
      "Training loss: 2955.3210752487184\n",
      "Test loss: 143099.187500 \n",
      "\n",
      "Epoch 844-------------------------------\n",
      "Training loss: 2562.7219984054564\n",
      "Test loss: 146685.078125 \n",
      "\n",
      "Epoch 845-------------------------------\n",
      "Training loss: 558.5403020858764\n",
      "Test loss: 147795.796875 \n",
      "\n",
      "Epoch 846-------------------------------\n",
      "Training loss: 2634.734149980545\n",
      "Test loss: 147927.015625 \n",
      "\n",
      "Epoch 847-------------------------------\n",
      "Training loss: 385.917937707901\n",
      "Test loss: 148453.953125 \n",
      "\n",
      "Epoch 848-------------------------------\n",
      "Training loss: 1490.9841783046722\n",
      "Test loss: 146844.656250 \n",
      "\n",
      "Epoch 849-------------------------------\n",
      "Training loss: 1847.2026885032653\n",
      "Test loss: 146862.718750 \n",
      "\n",
      "Epoch 850-------------------------------\n",
      "Training loss: 2291.5499781608582\n",
      "Test loss: 147167.796875 \n",
      "\n",
      "Epoch 851-------------------------------\n",
      "Training loss: 1228.4613847017288\n",
      "Test loss: 145355.765625 \n",
      "\n",
      "Epoch 852-------------------------------\n",
      "Training loss: 2575.7218977451325\n",
      "Test loss: 143622.031250 \n",
      "\n",
      "Epoch 853-------------------------------\n",
      "Training loss: 4118.196248531342\n",
      "Test loss: 147357.640625 \n",
      "\n",
      "Epoch 854-------------------------------\n",
      "Training loss: 1987.5266374588014\n",
      "Test loss: 147081.343750 \n",
      "\n",
      "Epoch 855-------------------------------\n",
      "Training loss: 2235.1764949798585\n",
      "Test loss: 146824.390625 \n",
      "\n",
      "Epoch 856-------------------------------\n",
      "Training loss: 792.6198957681656\n",
      "Test loss: 147633.609375 \n",
      "\n",
      "Epoch 857-------------------------------\n",
      "Training loss: 1063.90256690979\n",
      "Test loss: 146628.593750 \n",
      "\n",
      "Epoch 858-------------------------------\n",
      "Training loss: 1104.7096043109893\n",
      "Test loss: 147846.875000 \n",
      "\n",
      "Epoch 859-------------------------------\n",
      "Training loss: 1044.2727385997773\n",
      "Test loss: 147247.734375 \n",
      "\n",
      "Epoch 860-------------------------------\n",
      "Training loss: 1888.7732901573181\n",
      "Test loss: 148198.796875 \n",
      "\n",
      "Epoch 861-------------------------------\n",
      "Training loss: 1634.8255606651305\n",
      "Test loss: 147676.406250 \n",
      "\n",
      "Epoch 862-------------------------------\n",
      "Training loss: 704.463801240921\n",
      "Test loss: 147743.078125 \n",
      "\n",
      "Epoch 863-------------------------------\n",
      "Training loss: 2243.6694716691973\n",
      "Test loss: 147620.968750 \n",
      "\n",
      "Epoch 864-------------------------------\n",
      "Training loss: 5886.107701539993\n",
      "Test loss: 144031.593750 \n",
      "\n",
      "Epoch 865-------------------------------\n",
      "Training loss: 4973.097567367554\n",
      "Test loss: 145826.687500 \n",
      "\n",
      "Epoch 866-------------------------------\n",
      "Training loss: 2192.367130661011\n",
      "Test loss: 146840.015625 \n",
      "\n",
      "Epoch 867-------------------------------\n",
      "Training loss: 652.5670474052429\n",
      "Test loss: 146286.671875 \n",
      "\n",
      "Epoch 868-------------------------------\n",
      "Training loss: 1729.168777370453\n",
      "Test loss: 146817.812500 \n",
      "\n",
      "Epoch 869-------------------------------\n",
      "Training loss: 1350.649045562744\n",
      "Test loss: 146909.875000 \n",
      "\n",
      "Epoch 870-------------------------------\n",
      "Training loss: 1020.4293742656707\n",
      "Test loss: 146961.859375 \n",
      "\n",
      "Epoch 871-------------------------------\n",
      "Training loss: 2729.323597431183\n",
      "Test loss: 146992.078125 \n",
      "\n",
      "Epoch 872-------------------------------\n",
      "Training loss: 1449.0608973503113\n",
      "Test loss: 148146.453125 \n",
      "\n",
      "Epoch 873-------------------------------\n",
      "Training loss: 933.17349152565\n",
      "Test loss: 148156.000000 \n",
      "\n",
      "Epoch 874-------------------------------\n",
      "Training loss: 3063.8012389183045\n",
      "Test loss: 147199.812500 \n",
      "\n",
      "Epoch 875-------------------------------\n",
      "Training loss: 2283.989380073547\n",
      "Test loss: 147532.328125 \n",
      "\n",
      "Epoch 876-------------------------------\n",
      "Training loss: 1076.4436400413513\n",
      "Test loss: 147866.593750 \n",
      "\n",
      "Epoch 877-------------------------------\n",
      "Training loss: 889.1123085021973\n",
      "Test loss: 148323.484375 \n",
      "\n",
      "Epoch 878-------------------------------\n",
      "Training loss: 890.0569014072419\n",
      "Test loss: 148566.359375 \n",
      "\n",
      "Epoch 879-------------------------------\n",
      "Training loss: 532.2964506149292\n",
      "Test loss: 148254.250000 \n",
      "\n",
      "Epoch 880-------------------------------\n",
      "Training loss: 1078.262286925316\n",
      "Test loss: 147594.296875 \n",
      "\n",
      "Epoch 881-------------------------------\n",
      "Training loss: 1358.087375330925\n",
      "Test loss: 148709.125000 \n",
      "\n",
      "Epoch 882-------------------------------\n",
      "Training loss: 658.6378766536712\n",
      "Test loss: 147731.546875 \n",
      "\n",
      "Epoch 883-------------------------------\n",
      "Training loss: 3320.537870121002\n",
      "Test loss: 147960.343750 \n",
      "\n",
      "Epoch 884-------------------------------\n",
      "Training loss: 2879.0482031822203\n",
      "Test loss: 147843.562500 \n",
      "\n",
      "Epoch 885-------------------------------\n",
      "Training loss: 3382.167666244507\n",
      "Test loss: 147026.859375 \n",
      "\n",
      "Epoch 886-------------------------------\n",
      "Training loss: 3662.568269920349\n",
      "Test loss: 146705.281250 \n",
      "\n",
      "Epoch 887-------------------------------\n",
      "Training loss: 3132.6312231063844\n",
      "Test loss: 146806.015625 \n",
      "\n",
      "Epoch 888-------------------------------\n",
      "Training loss: 868.9332661628723\n",
      "Test loss: 145895.875000 \n",
      "\n",
      "Epoch 889-------------------------------\n",
      "Training loss: 2622.508850431442\n",
      "Test loss: 147461.031250 \n",
      "\n",
      "Epoch 890-------------------------------\n",
      "Training loss: 1414.396644306183\n",
      "Test loss: 146819.218750 \n",
      "\n",
      "Epoch 891-------------------------------\n",
      "Training loss: 1866.6319927215577\n",
      "Test loss: 146966.359375 \n",
      "\n",
      "Epoch 892-------------------------------\n",
      "Training loss: 1027.121520614624\n",
      "Test loss: 147338.671875 \n",
      "\n",
      "Epoch 893-------------------------------\n",
      "Training loss: 2074.4609264850615\n",
      "Test loss: 147891.703125 \n",
      "\n",
      "Epoch 894-------------------------------\n",
      "Training loss: 339.7969647407532\n",
      "Test loss: 148123.000000 \n",
      "\n",
      "Epoch 895-------------------------------\n",
      "Training loss: 819.1536774635315\n",
      "Test loss: 148192.937500 \n",
      "\n",
      "Epoch 896-------------------------------\n",
      "Training loss: 2747.015253639221\n",
      "Test loss: 148059.593750 \n",
      "\n",
      "Epoch 897-------------------------------\n",
      "Training loss: 815.0486978292465\n",
      "Test loss: 148310.171875 \n",
      "\n",
      "Epoch 898-------------------------------\n",
      "Training loss: 2665.9603838920593\n",
      "Test loss: 147505.937500 \n",
      "\n",
      "Epoch 899-------------------------------\n",
      "Training loss: 1759.2663731575012\n",
      "Test loss: 147443.328125 \n",
      "\n",
      "Epoch 900-------------------------------\n",
      "Training loss: 1773.204657816887\n",
      "Test loss: 147954.656250 \n",
      "\n",
      "Epoch 901-------------------------------\n",
      "Training loss: 1606.3210484981537\n",
      "Test loss: 147161.625000 \n",
      "\n",
      "Epoch 902-------------------------------\n",
      "Training loss: 1349.3709554672241\n",
      "Test loss: 147999.828125 \n",
      "\n",
      "Epoch 903-------------------------------\n",
      "Training loss: 593.2370893001556\n",
      "Test loss: 147841.546875 \n",
      "\n",
      "Epoch 904-------------------------------\n",
      "Training loss: 2434.0498939991\n",
      "Test loss: 147645.421875 \n",
      "\n",
      "Epoch 905-------------------------------\n",
      "Training loss: 1041.4814177513122\n",
      "Test loss: 147926.312500 \n",
      "\n",
      "Epoch 906-------------------------------\n",
      "Training loss: 1024.8175470352173\n",
      "Test loss: 146639.078125 \n",
      "\n",
      "Epoch 907-------------------------------\n",
      "Training loss: 1552.1834943294525\n",
      "Test loss: 148554.031250 \n",
      "\n",
      "Epoch 908-------------------------------\n",
      "Training loss: 2472.414018535614\n",
      "Test loss: 147386.343750 \n",
      "\n",
      "Epoch 909-------------------------------\n",
      "Training loss: 2875.851160335541\n",
      "Test loss: 148130.203125 \n",
      "\n",
      "Epoch 910-------------------------------\n",
      "Training loss: 4053.4188177108763\n",
      "Test loss: 147180.906250 \n",
      "\n",
      "Epoch 911-------------------------------\n",
      "Training loss: 1525.7741228103637\n",
      "Test loss: 146082.750000 \n",
      "\n",
      "Epoch 912-------------------------------\n",
      "Training loss: 2038.2753359794617\n",
      "Test loss: 146493.031250 \n",
      "\n",
      "Epoch 913-------------------------------\n",
      "Training loss: 2283.998112678528\n",
      "Test loss: 147622.656250 \n",
      "\n",
      "Epoch 914-------------------------------\n",
      "Training loss: 1565.2144696235657\n",
      "Test loss: 148163.546875 \n",
      "\n",
      "Epoch 915-------------------------------\n",
      "Training loss: 2339.3416759967804\n",
      "Test loss: 146606.250000 \n",
      "\n",
      "Epoch 916-------------------------------\n",
      "Training loss: 587.3011742591858\n",
      "Test loss: 144110.953125 \n",
      "\n",
      "Epoch 917-------------------------------\n",
      "Training loss: 1915.2039083480836\n",
      "Test loss: 148518.453125 \n",
      "\n",
      "Epoch 918-------------------------------\n",
      "Training loss: 674.4158916950225\n",
      "Test loss: 148037.671875 \n",
      "\n",
      "Epoch 919-------------------------------\n",
      "Training loss: 1306.2378718614577\n",
      "Test loss: 145748.390625 \n",
      "\n",
      "Epoch 920-------------------------------\n",
      "Training loss: 1535.0780179739\n",
      "Test loss: 148605.390625 \n",
      "\n",
      "Epoch 921-------------------------------\n",
      "Training loss: 680.8996150970459\n",
      "Test loss: 148548.625000 \n",
      "\n",
      "Epoch 922-------------------------------\n",
      "Training loss: 1965.048285317421\n",
      "Test loss: 148616.718750 \n",
      "\n",
      "Epoch 923-------------------------------\n",
      "Training loss: 3282.418505573273\n",
      "Test loss: 146364.421875 \n",
      "\n",
      "Epoch 924-------------------------------\n",
      "Training loss: 1918.5059849739075\n",
      "Test loss: 145823.296875 \n",
      "\n",
      "Epoch 925-------------------------------\n",
      "Training loss: 928.6193226337433\n",
      "Test loss: 146441.703125 \n",
      "\n",
      "Epoch 926-------------------------------\n",
      "Training loss: 4556.123032283783\n",
      "Test loss: 146523.406250 \n",
      "\n",
      "Epoch 927-------------------------------\n",
      "Training loss: 1169.601153755188\n",
      "Test loss: 146922.031250 \n",
      "\n",
      "Epoch 928-------------------------------\n",
      "Training loss: 1628.9660822153091\n",
      "Test loss: 147828.796875 \n",
      "\n",
      "Epoch 929-------------------------------\n",
      "Training loss: 1355.0047146558761\n",
      "Test loss: 147593.906250 \n",
      "\n",
      "Epoch 930-------------------------------\n",
      "Training loss: 1291.1896474838256\n",
      "Test loss: 146668.953125 \n",
      "\n",
      "Epoch 931-------------------------------\n",
      "Training loss: 2231.2088327407837\n",
      "Test loss: 147767.296875 \n",
      "\n",
      "Epoch 932-------------------------------\n",
      "Training loss: 3119.6031608581543\n",
      "Test loss: 148037.000000 \n",
      "\n",
      "Epoch 933-------------------------------\n",
      "Training loss: 879.7515313148499\n",
      "Test loss: 147252.531250 \n",
      "\n",
      "Epoch 934-------------------------------\n",
      "Training loss: 685.4938185691833\n",
      "Test loss: 147744.140625 \n",
      "\n",
      "Epoch 935-------------------------------\n",
      "Training loss: 851.9134335041047\n",
      "Test loss: 147915.734375 \n",
      "\n",
      "Epoch 936-------------------------------\n",
      "Training loss: 2164.3975722789764\n",
      "Test loss: 147407.671875 \n",
      "\n",
      "Epoch 937-------------------------------\n",
      "Training loss: 2483.187597513199\n",
      "Test loss: 144348.656250 \n",
      "\n",
      "Epoch 938-------------------------------\n",
      "Training loss: 5380.920144081116\n",
      "Test loss: 147039.937500 \n",
      "\n",
      "Epoch 939-------------------------------\n",
      "Training loss: 1347.7722473144531\n",
      "Test loss: 146678.312500 \n",
      "\n",
      "Epoch 940-------------------------------\n",
      "Training loss: 1565.6450735092162\n",
      "Test loss: 147589.546875 \n",
      "\n",
      "Epoch 941-------------------------------\n",
      "Training loss: 1131.9219604969026\n",
      "Test loss: 147885.203125 \n",
      "\n",
      "Epoch 942-------------------------------\n",
      "Training loss: 4190.335602092743\n",
      "Test loss: 146485.187500 \n",
      "\n",
      "Epoch 943-------------------------------\n",
      "Training loss: 1619.854605960846\n",
      "Test loss: 148061.484375 \n",
      "\n",
      "Epoch 944-------------------------------\n",
      "Training loss: 1312.624772119522\n",
      "Test loss: 148436.656250 \n",
      "\n",
      "Epoch 945-------------------------------\n",
      "Training loss: 553.7978684425354\n",
      "Test loss: 147710.593750 \n",
      "\n",
      "Epoch 946-------------------------------\n",
      "Training loss: 1331.4361371278762\n",
      "Test loss: 146190.625000 \n",
      "\n",
      "Epoch 947-------------------------------\n",
      "Training loss: 1863.290940618515\n",
      "Test loss: 142411.765625 \n",
      "\n",
      "Epoch 948-------------------------------\n",
      "Training loss: 3877.5098741531374\n",
      "Test loss: 146734.437500 \n",
      "\n",
      "Epoch 949-------------------------------\n",
      "Training loss: 539.5208231925965\n",
      "Test loss: 147768.578125 \n",
      "\n",
      "Epoch 950-------------------------------\n",
      "Training loss: 1253.34408121109\n",
      "Test loss: 147923.843750 \n",
      "\n",
      "Epoch 951-------------------------------\n",
      "Training loss: 916.9768932342529\n",
      "Test loss: 147959.093750 \n",
      "\n",
      "Epoch 952-------------------------------\n",
      "Training loss: 1146.3755595207215\n",
      "Test loss: 148636.609375 \n",
      "\n",
      "Epoch 953-------------------------------\n",
      "Training loss: 989.3190729141236\n",
      "Test loss: 148330.968750 \n",
      "\n",
      "Epoch 954-------------------------------\n",
      "Training loss: 1344.511956715584\n",
      "Test loss: 148079.437500 \n",
      "\n",
      "Epoch 955-------------------------------\n",
      "Training loss: 1544.2809847831727\n",
      "Test loss: 147815.171875 \n",
      "\n",
      "Epoch 956-------------------------------\n",
      "Training loss: 738.9316266059875\n",
      "Test loss: 145227.906250 \n",
      "\n",
      "Epoch 957-------------------------------\n",
      "Training loss: 2767.5540755271913\n",
      "Test loss: 147029.109375 \n",
      "\n",
      "Epoch 958-------------------------------\n",
      "Training loss: 1548.7485701084138\n",
      "Test loss: 147908.296875 \n",
      "\n",
      "Epoch 959-------------------------------\n",
      "Training loss: 708.6819581031799\n",
      "Test loss: 148262.296875 \n",
      "\n",
      "Epoch 960-------------------------------\n",
      "Training loss: 835.8428839683532\n",
      "Test loss: 148659.093750 \n",
      "\n",
      "Epoch 961-------------------------------\n",
      "Training loss: 851.6047375679016\n",
      "Test loss: 146916.328125 \n",
      "\n",
      "Epoch 962-------------------------------\n",
      "Training loss: 1272.3174494504929\n",
      "Test loss: 148317.437500 \n",
      "\n",
      "Epoch 963-------------------------------\n",
      "Training loss: 2034.7646236419678\n",
      "Test loss: 148380.656250 \n",
      "\n",
      "Epoch 964-------------------------------\n",
      "Training loss: 3212.2221161842344\n",
      "Test loss: 147870.250000 \n",
      "\n",
      "Epoch 965-------------------------------\n",
      "Training loss: 485.0495062828064\n",
      "Test loss: 147808.859375 \n",
      "\n",
      "Epoch 966-------------------------------\n",
      "Training loss: 4048.8902339696883\n",
      "Test loss: 146460.781250 \n",
      "\n",
      "Epoch 967-------------------------------\n",
      "Training loss: 903.1525850772857\n",
      "Test loss: 146436.828125 \n",
      "\n",
      "Epoch 968-------------------------------\n",
      "Training loss: 2256.640481185913\n",
      "Test loss: 147340.765625 \n",
      "\n",
      "Epoch 969-------------------------------\n",
      "Training loss: 2504.1522393703463\n",
      "Test loss: 145456.156250 \n",
      "\n",
      "Epoch 970-------------------------------\n",
      "Training loss: 1830.6669969558716\n",
      "Test loss: 147657.843750 \n",
      "\n",
      "Epoch 971-------------------------------\n",
      "Training loss: 1881.8219458580018\n",
      "Test loss: 146964.187500 \n",
      "\n",
      "Epoch 972-------------------------------\n",
      "Training loss: 2304.207084751129\n",
      "Test loss: 147858.390625 \n",
      "\n",
      "Epoch 973-------------------------------\n",
      "Training loss: 2802.801591491699\n",
      "Test loss: 144456.375000 \n",
      "\n",
      "Epoch 974-------------------------------\n",
      "Training loss: 1136.9045667648315\n",
      "Test loss: 147770.468750 \n",
      "\n",
      "Epoch 975-------------------------------\n",
      "Training loss: 3103.815748310089\n",
      "Test loss: 148086.578125 \n",
      "\n",
      "Epoch 976-------------------------------\n",
      "Training loss: 1649.0505771160126\n",
      "Test loss: 148020.828125 \n",
      "\n",
      "Epoch 977-------------------------------\n",
      "Training loss: 2016.4765936613082\n",
      "Test loss: 147513.578125 \n",
      "\n",
      "Epoch 978-------------------------------\n",
      "Training loss: 2998.507136774063\n",
      "Test loss: 146517.796875 \n",
      "\n",
      "Epoch 979-------------------------------\n",
      "Training loss: 818.043132019043\n",
      "Test loss: 147885.734375 \n",
      "\n",
      "Epoch 980-------------------------------\n",
      "Training loss: 2721.3336540699006\n",
      "Test loss: 147254.593750 \n",
      "\n",
      "Epoch 981-------------------------------\n",
      "Training loss: 1405.7172654628753\n",
      "Test loss: 147838.968750 \n",
      "\n",
      "Epoch 982-------------------------------\n",
      "Training loss: 1884.4992714881896\n",
      "Test loss: 148055.750000 \n",
      "\n",
      "Epoch 983-------------------------------\n",
      "Training loss: 669.4464647293091\n",
      "Test loss: 148344.593750 \n",
      "\n",
      "Epoch 984-------------------------------\n",
      "Training loss: 1282.9894021987916\n",
      "Test loss: 148005.875000 \n",
      "\n",
      "Epoch 985-------------------------------\n",
      "Training loss: 1099.429793381691\n",
      "Test loss: 149314.718750 \n",
      "\n",
      "Epoch 986-------------------------------\n",
      "Training loss: 740.4004950523376\n",
      "Test loss: 146940.796875 \n",
      "\n",
      "Epoch 987-------------------------------\n",
      "Training loss: 848.6178529977799\n",
      "Test loss: 148620.828125 \n",
      "\n",
      "Epoch 988-------------------------------\n",
      "Training loss: 597.9820130348205\n",
      "Test loss: 148285.296875 \n",
      "\n",
      "Epoch 989-------------------------------\n",
      "Training loss: 1605.9236599445344\n",
      "Test loss: 148611.093750 \n",
      "\n",
      "Epoch 990-------------------------------\n",
      "Training loss: 1620.9524154424666\n",
      "Test loss: 148445.765625 \n",
      "\n",
      "Epoch 991-------------------------------\n",
      "Training loss: 2299.9705085277556\n",
      "Test loss: 146618.218750 \n",
      "\n",
      "Epoch 992-------------------------------\n",
      "Training loss: 677.6112329483033\n",
      "Test loss: 148416.750000 \n",
      "\n",
      "Epoch 993-------------------------------\n",
      "Training loss: 1395.308472919464\n",
      "Test loss: 148455.562500 \n",
      "\n",
      "Epoch 994-------------------------------\n",
      "Training loss: 2129.6994194030763\n",
      "Test loss: 146411.593750 \n",
      "\n",
      "Epoch 995-------------------------------\n",
      "Training loss: 3463.4792437076567\n",
      "Test loss: 148093.281250 \n",
      "\n",
      "Epoch 996-------------------------------\n",
      "Training loss: 853.5006939172745\n",
      "Test loss: 148431.718750 \n",
      "\n",
      "Epoch 997-------------------------------\n",
      "Training loss: 1128.1731122016906\n",
      "Test loss: 147759.796875 \n",
      "\n",
      "Epoch 998-------------------------------\n",
      "Training loss: 3398.74183216095\n",
      "Test loss: 146538.984375 \n",
      "\n",
      "Epoch 999-------------------------------\n",
      "Training loss: 2763.195470523834\n",
      "Test loss: 147351.968750 \n",
      "\n",
      "Epoch 1000-------------------------------\n",
      "Training loss: 1226.3501044273376\n",
      "Test loss: 147155.421875 \n",
      "\n",
      "Training done!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "model = Net(n_hl=2, n_npl=20).to(device)\n",
    "print(model)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=2e-5, weight_decay=3e-2)\n",
    "epochs = 1000\n",
    "batch_size = 40\n",
    "train_loss, test_loss = [], []\n",
    "strain_inp = np.vstack((strain, strain_sum)).T\n",
    "x_train, x_test, y_train, y_test = train_test_split(strain_inp, stress, train_size=0.8)\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f'Epoch {t+1}-------------------------------')\n",
    "    train_loss.append(train(x_train, y_train, batch_size, model, loss_fn, optimizer))\n",
    "    test_loss.append(test(x_test, y_test, model, loss_fn))\n",
    "print('Training done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Test loss [${MPa}^2$]')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(train_loss, label='Train loss')\n",
    "ax.plot(test_loss, label='Test loss')\n",
    "ax.legend(frameon=False)\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Test loss [${MPa}^2$]')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model state to FCNN_J2.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), 'FCNN_J2.pth')\n",
    "print('Saved model state to FCNN_J2.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU + FCNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class GRU_FCNN(nn.Module):\n",
    "    def __init__(self, input_size, gru_hidden_size, num_gru_layers, fcnn_hidden_sizes, output_size, dropout_prob=0.0):\n",
    "        super(GRU_FCNN, self).__init__()\n",
    "        self.gru = nn.GRU(input_size, gru_hidden_size, num_gru_layers, batch_first=True, dropout=dropout_prob)\n",
    "        self.fcnn_layers = nn.ModuleList()\n",
    "\n",
    "        # Add FCNN layers\n",
    "        input_fcnn_size = gru_hidden_size\n",
    "        for hidden_size in fcnn_hidden_sizes:\n",
    "            self.fcnn_layers.append(nn.Linear(input_fcnn_size, hidden_size))\n",
    "            self.fcnn_layers.append(nn.ReLU())\n",
    "            input_fcnn_size = hidden_size\n",
    "\n",
    "        self.fcnn_layers.append(nn.Linear(input_fcnn_size, output_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # GRU layer\n",
    "        gru_out, _ = self.gru(x)\n",
    "\n",
    "        # Take the output from the last time step\n",
    "        fcnn_in = gru_out[:, -1, :]\n",
    "\n",
    "        # FCNN layers\n",
    "        for layer in self.fcnn_layers:\n",
    "            fcnn_in = layer(fcnn_in)\n",
    "\n",
    "        return fcnn_in"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
